{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ce5pQK3bFn_"
   },
   "source": [
    "# Assignment 1\n",
    "In this assignment you will be creating tools for learning and testing language models.\n",
    "The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwG8v-Ll49KM"
   },
   "source": [
    "*As a preparation for this task, download the data files from the course git repository.\n",
    "\n",
    "The relevant files are under **lm-languages-data-new**:\n",
    "\n",
    "\n",
    "*   en.csv (or the equivalent JSON file)\n",
    "*   es.csv (or the equivalent JSON file)\n",
    "*   fr.csv (or the equivalent JSON file)\n",
    "*   in.csv (or the equivalent JSON file)\n",
    "*   it.csv (or the equivalent JSON file)\n",
    "*   nl.csv (or the equivalent JSON file)\n",
    "*   pt.csv (or the equivalent JSON file)\n",
    "*   tl.csv (or the equivalent JSON file)\n",
    "*   test.csv (or the equivalent JSON file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import time\n",
    "import glob\n",
    "import os \n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xC-87z2GWMq",
    "outputId": "7b7f40be-bf9b-4d6c-da81-25d60d710a75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nlp-course' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kfirbar/nlp-course.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOVb4IhsqimJ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Important note: please use only the files under lm-languages-data-new and NOT under lm-languages-data**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYdhPfbAGkip",
    "outputId": "af6566c6-e6e6-409a-c569-8fab9bdf400e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls nlp-course/lm-languages-data-new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {'en_df': 'en.csv',\n",
    "              'es_df': 'es.csv',\n",
    "              'fr_df': 'fr.csv',\n",
    "              'in_df': 'in.csv',\n",
    "              'it_df': 'it.csv',\n",
    "              'nl_df': 'nl.csv',\n",
    "              'pt_df': 'pt.csv',\n",
    "              'tl_df': 'tl.csv'}\n",
    "\n",
    "    \n",
    "directory = r'nlp-course\\lm-languages-data'    \n",
    "train_csv_files =  glob.glob(directory+ '\\\\*.csv')\n",
    "data_files =  {}\n",
    "for i_file in train_csv_files:\n",
    "    file_name_with_ending = os.path.basename(i_file)\n",
    "    file_name = os.path.splitext(file_name_with_ending)[0]\n",
    "    data_files[file_name+ '_df'] = f''+i_file\n",
    "    \n",
    "    \n",
    "languages_list = list(data_files.keys())\n",
    "start_token = '↠'\n",
    "end_token = '↞'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ashyu_mT28o6"
   },
   "source": [
    "**Part 1**\n",
    "\n",
    "Write a function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. **Our token definition is a single UTF-8 encoded character**. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xCfzsITW8Yaj"
   },
   "outputs": [],
   "source": [
    "def preprocess(data_files):\n",
    "    \"\"\"\n",
    "    data frame is table from 2 columns:\n",
    "        1. tweet id\n",
    "        2. tweet text\n",
    "    \"\"\"  \n",
    "    tokens = []\n",
    "    for path in data_files.values():\n",
    "        df = pd.read_csv(path)\n",
    "        if tokens.__len__() == 0 :\n",
    "            columns_list = df.columns.to_list()\n",
    "        for text in df[columns_list[-1]].values:\n",
    "            tokens.extend(list(text))\n",
    "    return list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = preprocess(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb2PGj0Yc2TY"
   },
   "source": [
    "**Part 2**\n",
    "\n",
    "Write a function lm that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant n-1 sequences, and the values are dictionaries with the n_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
    "\n",
    "{\n",
    "  \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25},\n",
    "  \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1}\n",
    "}\n",
    "\n",
    "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
    "\n",
    "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "def tweets_to_text(data_file_path, n):\n",
    "    \"\"\"\n",
    "    data frame is table from 2 columns:\n",
    "        1. tweet id\n",
    "        2. tweet text\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(r''+ data_file_path)\n",
    "    debug = True\n",
    "    if debug == True:\n",
    "        df = df[0:100]\n",
    "    columns_list = df.columns.to_list()\n",
    "    tweets_list = df[columns_list[-1]].apply(lambda x: start_token + x + end_token).values\n",
    "    text = ''.join(tweets_list)\n",
    "    \n",
    "    text = start_token * (n-1) + text + end_token * (n-1)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kMC_u8eQbVvZ"
   },
   "outputs": [],
   "source": [
    "def lm(n, vocabulary, data_file_path, add_one):\n",
    "    # n - the n-gram to use (e.g., 1 - unigram, 2 - bigram, etc.)\n",
    "    # vocabulary - the vocabulary list (which you should use for calculating add_one smoothing)\n",
    "    # data_file_path - the data_file from which we record probabilities for our model\n",
    "    # add_one - True/False (use add_one smoothing or not)\n",
    "  \n",
    "    lm_dict = {}\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    text = tweets_to_text(data_file_path, n)\n",
    "\n",
    "    # Extract n - 1 length substrings\n",
    "    n_1_gram = [text[i: i + n-1] for i in range(len(text) - n-1)]\n",
    "    counter_obj_n_1_gram = dict(Counter(n_1_gram))\n",
    "\n",
    "    # Extract n length substrings\n",
    "    n_gram = [text[i: i + n] for i in range(len(text) - n)]\n",
    "    counter_obj_n_gram = dict(Counter(n_gram))\n",
    "\n",
    "    for key in counter_obj_n_1_gram.keys():\n",
    "        inner_dict = {}\n",
    "        if add_one:\n",
    "            gen = (key_1 for key_1 in counter_obj_n_gram.keys() if key_1[0:n-1] == key)\n",
    "            for key_1 in gen:\n",
    "                val = (int(counter_obj_n_gram[key_1]) + 1) / (int(counter_obj_n_1_gram[key]) + V)\n",
    "                inner_dict[key_1[-1]] = val\n",
    "\n",
    "            gen = (token for token in vocabulary if not(token in inner_dict))\n",
    "            for key_1 in gen:\n",
    "                val = 1 /  (int(counter_obj_n_1_gram[key]) + V)\n",
    "                inner_dict[key_1[-1]] = val\n",
    "\n",
    "        else:\n",
    "            gen = (key_1 for key_1 in counter_obj_n_gram.keys() if key_1[0:n-1] == key)\n",
    "            sum_vals = 0\n",
    "            for key_1 in gen:\n",
    "                val = int(counter_obj_n_gram[key_1]) / int(counter_obj_n_1_gram[key])\n",
    "                inner_dict[key_1[-1]] = val\n",
    "                sum_vals += val\n",
    "            #print(sum_vals)\n",
    "            #print(sum(list(inner_dict.values())))\n",
    "        lm_dict[key] = inner_dict.copy()\n",
    "\n",
    "    return lm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files['en_df']\n",
    "os.path.exists(data_files['en_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = lm(1, vocabulary, data_files['en_df'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M8TchtI22I3"
   },
   "source": [
    "**Part 3**\n",
    "\n",
    "Write a function *eval* that returns the perplexity of a model (dictionary) running over a given data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F0kkMn328-lJ"
   },
   "outputs": [],
   "source": [
    "def eval(n, model, data_file):\n",
    "    # n - the n-gram that you used to build your model (must be the same number)\n",
    "    # model - the dictionary (model) to use for calculating perplexity\n",
    "    # data_file - the tweets file that you wish to claculate a perplexity score for\n",
    "\n",
    "    # read file\n",
    "    if os.path.exists(data_file):\n",
    "        text = tweets_to_text(data_file, n)\n",
    "    else:\n",
    "        text = data_file\n",
    "    # Extract n length substrings\n",
    "    n_gram = [text[i: i + n] for i in range(len(text) - n)]\n",
    "\n",
    "    model_keys = model.keys()\n",
    "    entropy = 0 \n",
    "    for i_letter in n_gram:\n",
    "        if i_letter[0] in model_keys: \n",
    "            i_letter_model = model[i_letter[0]]\n",
    "            if i_letter[1] in i_letter_model.keys():\n",
    "                second_letter_prob = i_letter_model[i_letter[1]]\n",
    "                entropy += -np.log2(second_letter_prob)\n",
    "            else:\n",
    "                entropy += 0\n",
    "\n",
    "        else:\n",
    "              entropy += 0\n",
    "    entropy = entropy/n_gram.__len__()\n",
    "    perplexity_score = 2**(entropy)\n",
    "    return perplexity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enGmtLE3921p"
   },
   "source": [
    "**Part 4**\n",
    "\n",
    "Write a function *match* that creates a model for every relevant language, using a specific value of *n* and *add_one*. Then, calculate the perplexity of all possible pairs (e.g., en model applied on the data files en ,es, fr, in, it, nl, pt, tl; es model applied on the data files en, es...). This function should return a pandas DataFrame with columns [en ,es, fr, in, it, nl, pt, tl] and every row should be labeled with one of the languages. Then, the values are the relevant perplexity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "caAxLE9s_fvn"
   },
   "outputs": [],
   "source": [
    "def match(n, add_one, data_files):\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "    model_dict = {}\n",
    "    result_dict = {}\n",
    "    vocabulary = preprocess(data_files)\n",
    "    for i_language_model in languages_list:\n",
    "        \n",
    "        i_model = lm(n, vocabulary, data_files[i_language_model], add_one)\n",
    "        model_dict[i_language_model] = i_model\n",
    "        result_dict[i_language_model] = {}\n",
    "\n",
    "        for i_language_test in languages_list:\n",
    "            i_language_model_i_score = eval(n, i_model, data_files[i_language_test])\n",
    "            result_dict[i_language_model][i_language_test] = i_language_model_i_score\n",
    "    print('summary for matching (add_one = '+ str(add_one) +') model perlexity score per model and test language :\\n')\n",
    "    perlexity_df = pd.DataFrame(result_dict)\n",
    "    print(perlexity_df)\n",
    "    #TODO\n",
    "    return perlexity_df, model_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waGMwA8H_n17"
   },
   "source": [
    "**Part 5**\n",
    "\n",
    "Run match with *n* values 1-4, once with add_one and once without, and print the 8 tables to this notebook, one after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nk32naXyAMdl"
   },
   "outputs": [],
   "source": [
    " \n",
    "def run_match(data_files):\n",
    "    full_model_dict = {}\n",
    "    for n in range(2,3):\n",
    "\n",
    "    #for n in range(1,5):\n",
    "        full_model_dict[n] = {}\n",
    "        add_one = True\n",
    "        perlexity_df, model_dict = match(n, add_one, data_files)\n",
    "        full_model_dict[n][add_one] = model_dict \n",
    "        add_one = False\n",
    "        perlexity_df, model_dict = match(n, add_one, data_files)\n",
    "        full_model_dict[n][add_one] = model_dict\n",
    "    return full_model_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = True) model perlexity score per model and test language :\n",
      "\n",
      "            en_df       es_df       fr_df       in_df       it_df       nl_df  \\\n",
      "en_df  119.847616  172.456936  160.024450  178.603179  167.717434  155.372049   \n",
      "es_df  144.131361   98.919525  114.906593  154.211327  111.427802  148.309887   \n",
      "fr_df  148.011517  131.084709   96.341540  170.935224  134.056872  147.913061   \n",
      "in_df  174.136575  180.383232  179.114805  109.361124  168.894573  166.339083   \n",
      "it_df  146.570739  119.584133  128.769837  154.611482   93.924642  153.428494   \n",
      "nl_df  166.867868  178.768303  163.756426  177.248636  172.014415  103.331290   \n",
      "pt_df  149.276980  124.053789  123.215923  156.791560  115.651035  150.575842   \n",
      "tl_df  192.132873  205.796949  212.642170  163.325598  199.712385  197.610896   \n",
      "\n",
      "            pt_df       tl_df  \n",
      "en_df  199.260938  199.923476  \n",
      "es_df  135.382024  184.267173  \n",
      "fr_df  159.608751  204.290610  \n",
      "in_df  200.819618  164.304573  \n",
      "it_df  140.239670  183.269813  \n",
      "nl_df  204.158802  219.533920  \n",
      "pt_df  110.749903  184.569516  \n",
      "tl_df  230.828136  135.360938  \n",
      "summary for matching (add_one = False) model perlexity score per model and test language :\n",
      "\n",
      "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
      "en_df  13.682627  10.723084  11.110256  11.685063  10.556161  11.705231   \n",
      "es_df  11.353397  12.571671  10.464176  11.411623   9.559747  11.340040   \n",
      "fr_df   9.933661   9.993254  12.933093  10.808323   9.921803  10.398169   \n",
      "in_df  12.602389  12.420921  12.754006  13.797581  11.446151  12.880179   \n",
      "it_df  11.546829  10.294436  11.370067  11.991167  12.825286  12.758549   \n",
      "nl_df  10.775454  11.502855  10.534623  11.505419  10.984255  13.579531   \n",
      "pt_df  11.357817  10.271415  11.349678  12.012929   9.762028  13.012985   \n",
      "tl_df  11.507011  11.391745  12.178064  10.077523  10.281739  12.299585   \n",
      "\n",
      "           pt_df      tl_df  \n",
      "en_df   9.852434  10.806505  \n",
      "es_df   9.173228  10.615895  \n",
      "fr_df   9.176869   9.841632  \n",
      "in_df  11.072140  10.776762  \n",
      "it_df   9.711638  10.648164  \n",
      "nl_df  10.604270  10.464041  \n",
      "pt_df  12.460809  11.085499  \n",
      "tl_df  10.212382  13.178943  \n"
     ]
    }
   ],
   "source": [
    "model_dict = run_match(data_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cg4h5Cl0q2nR"
   },
   "source": [
    "**Part 6**\n",
    "\n",
    "Each line in the file test.csv contains a sentence and the language it belongs to. Write a function that uses your language models to classify the correct language of each sentence.\n",
    "\n",
    "Important note regarding the grading of this section: this is an open question, where a different solution will yield different accuracy scores. any solution that is not trivial (e.g. returning 'en' in all cases) will be excepted. We do reserve the right to give bonus points to exceptionally good/creative solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! ls nlp-course\\lm-languages-data-new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = r'nlp-course\\lm-languages-data-new'\n",
    "test_csv_files =  glob.glob(test_folder + '\\\\*.csv')\n",
    "test_files =  {}\n",
    "for i_file in test_csv_files:\n",
    "    file_name_with_ending = os.path.basename(i_file)\n",
    "    file_name = os.path.splitext(file_name_with_ending)[0]\n",
    "    test_files[file_name + '_df'] = f'' + i_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qD6IRIQLrlZF"
   },
   "outputs": [],
   "source": [
    "def match_test(n, model_dict, data_file_path, add_one):\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "    #data_file_path = r\"C:\\MSC\\NLP2\\nlp-course\\lm-languages-data-new\\test.csv\"\n",
    "    senstences_list = pd.read_csv(data_file_path)['tweet_text'].to_list()\n",
    "    lines = [] \n",
    "    result_dict = {}\n",
    "    for i_language_model in languages_list:\n",
    "        i_model = model_dict[n][add_one][i_language_model]\n",
    "        result_dict[i_language_model] = {}\n",
    "        \n",
    "        for i_test_senstence in senstences_list:\n",
    "            i_sentence_model_i_score = eval(n, i_model, i_test_senstence)\n",
    "            result_dict[i_language_model][i_test_senstence] = i_sentence_model_i_score\n",
    "    # print('summary for '+ i_language_model +' model perlexity score for each language:\\n')\n",
    "    perlexity_df = pd.DataFrame(result_dict)\n",
    "    print(perlexity_df)\n",
    "    #TODO\n",
    "    return perlexity_df\n",
    "\n",
    "\n",
    "def classify(n, model_dict, data_file_path, add_one):\n",
    "    # TODO\n",
    "    match_dict  = match_test(n, model_dict, data_file_path, add_one)\n",
    "    return match_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        en_df      es_df  \\\n",
      "RT @jarsofshine: In 08 I had a volunteer who ha...  13.218897  12.717863   \n",
      "IN OGNI CASO CON LE PAGHE CHE GIRANO IN Africa ...  13.589453  11.559213   \n",
      "@jaynaldmase @acobasilianne @dingDANGdantes @da...  12.682247  15.440703   \n",
      "Daags voor @RondeVlaanderen, @VoltaClassic als ...  10.292917  10.338545   \n",
      "RT @ertsul20: Susuportahan kita hanggang sa dul...   9.604915  11.345213   \n",
      "...                                                       ...        ...   \n",
      "La triste historia que inspiró \"Tu falta de que...   8.978503   8.646596   \n",
      "RT @ShahwalAdli_: Aku tak bersuara tak bermakna...  15.311230  11.681127   \n",
      "@Benji_Mascolo DEVI TAGLIARE QUEI CAPELLI 😠😡😠😂❤      5.653674  11.971246   \n",
      "Assistimos de camarote varias brigas ontem!         15.150401  12.096101   \n",
      "RT @ESPNNBA: #TheJump Distant Replay: 7 years a...   8.119801  11.433511   \n",
      "\n",
      "                                                        fr_df      in_df  \\\n",
      "RT @jarsofshine: In 08 I had a volunteer who ha...  16.451440  14.332960   \n",
      "IN OGNI CASO CON LE PAGHE CHE GIRANO IN Africa ...  13.693580   9.893253   \n",
      "@jaynaldmase @acobasilianne @dingDANGdantes @da...  12.867838  14.356114   \n",
      "Daags voor @RondeVlaanderen, @VoltaClassic als ...   8.776683  11.965725   \n",
      "RT @ertsul20: Susuportahan kita hanggang sa dul...  10.827068   7.904009   \n",
      "...                                                       ...        ...   \n",
      "La triste historia que inspiró \"Tu falta de que...   7.661016   9.203403   \n",
      "RT @ShahwalAdli_: Aku tak bersuara tak bermakna...  14.597656  11.861831   \n",
      "@Benji_Mascolo DEVI TAGLIARE QUEI CAPELLI 😠😡😠😂❤     11.281229   8.123352   \n",
      "Assistimos de camarote varias brigas ontem!         13.642727  18.263338   \n",
      "RT @ESPNNBA: #TheJump Distant Replay: 7 years a...  13.004838   9.603866   \n",
      "\n",
      "                                                        it_df      nl_df  \\\n",
      "RT @jarsofshine: In 08 I had a volunteer who ha...  13.027950  18.410104   \n",
      "IN OGNI CASO CON LE PAGHE CHE GIRANO IN Africa ...  10.289250  19.458916   \n",
      "@jaynaldmase @acobasilianne @dingDANGdantes @da...  16.116196  16.965680   \n",
      "Daags voor @RondeVlaanderen, @VoltaClassic als ...  12.679103  10.147338   \n",
      "RT @ertsul20: Susuportahan kita hanggang sa dul...   8.238461   9.920722   \n",
      "...                                                       ...        ...   \n",
      "La triste historia que inspiró \"Tu falta de que...   7.442447   8.029897   \n",
      "RT @ShahwalAdli_: Aku tak bersuara tak bermakna...  13.783380  16.136689   \n",
      "@Benji_Mascolo DEVI TAGLIARE QUEI CAPELLI 😠😡😠😂❤      6.809464   9.436877   \n",
      "Assistimos de camarote varias brigas ontem!         14.736228  17.207666   \n",
      "RT @ESPNNBA: #TheJump Distant Replay: 7 years a...  13.800886  11.477299   \n",
      "\n",
      "                                                        pt_df      tl_df  \n",
      "RT @jarsofshine: In 08 I had a volunteer who ha...  11.693922  14.433633  \n",
      "IN OGNI CASO CON LE PAGHE CHE GIRANO IN Africa ...  11.726386  13.237698  \n",
      "@jaynaldmase @acobasilianne @dingDANGdantes @da...  15.257677  13.640707  \n",
      "Daags voor @RondeVlaanderen, @VoltaClassic als ...   9.313778  10.222071  \n",
      "RT @ertsul20: Susuportahan kita hanggang sa dul...   9.814584   8.030950  \n",
      "...                                                       ...        ...  \n",
      "La triste historia que inspiró \"Tu falta de que...   8.659001   8.899787  \n",
      "RT @ShahwalAdli_: Aku tak bersuara tak bermakna...  14.975529  14.471058  \n",
      "@Benji_Mascolo DEVI TAGLIARE QUEI CAPELLI 😠😡😠😂❤      7.796479  14.190756  \n",
      "Assistimos de camarote varias brigas ontem!         11.317116  16.376125  \n",
      "RT @ESPNNBA: #TheJump Distant Replay: 7 years a...   9.749484   9.007221  \n",
      "\n",
      "[7772 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "test_path = test_folder + '\\\\test.csv'\n",
    "clasification_result = classify(n, model_dict, test_path, False)\n",
    "\n",
    "# roni needed to yuield results from mat results\n",
    "#########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5ECmLd3rktZ"
   },
   "source": [
    "**Part 7**\n",
    "\n",
    "Calculate the F1 score of your output from part 6. (hint: you can use https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOBO3YQls66r"
   },
   "outputs": [],
   "source": [
    "def calc_f1(result):\n",
    "    data_file_path = f'nlp-course/lm-languages-data-new/test.csv'\n",
    "    labels = pd.read_csv(data_file_path).get('label')\n",
    "    print(list(labels))\n",
    "    return f1_score(list(labels), clasification_result,average=\"micro\")\n",
    "\n",
    "  # TODO\n",
    "\n",
    "calc_f1(clasification_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEtckSWNANqW"
   },
   "source": [
    "# **Good luck!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
