{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ce5pQK3bFn_"
   },
   "source": [
    "# Assignment 1\n",
    "In this assignment you will be creating tools for learning and testing language models.\n",
    "The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwG8v-Ll49KM"
   },
   "source": [
    "*As a preparation for this task, download the data files from the course git repository.\n",
    "\n",
    "The relevant files are under **lm-languages-data-new**:\n",
    "\n",
    "\n",
    "*   en.csv (or the equivalent JSON file)\n",
    "*   es.csv (or the equivalent JSON file)\n",
    "*   fr.csv (or the equivalent JSON file)\n",
    "*   in.csv (or the equivalent JSON file)\n",
    "*   it.csv (or the equivalent JSON file)\n",
    "*   nl.csv (or the equivalent JSON file)\n",
    "*   pt.csv (or the equivalent JSON file)\n",
    "*   tl.csv (or the equivalent JSON file)\n",
    "*   test.csv (or the equivalent JSON file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import glob\n",
    "import os \n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xC-87z2GWMq",
    "outputId": "7b7f40be-bf9b-4d6c-da81-25d60d710a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nlp-course' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kfirbar/nlp-course.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOVb4IhsqimJ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Important note: please use only the files under lm-languages-data-new and NOT under lm-languages-data**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYdhPfbAGkip",
    "outputId": "af6566c6-e6e6-409a-c569-8fab9bdf400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en.csv     es.json    in.csv     it.json    pt.csv     test.json  tl.csv\n",
      "en.json    fr.csv     in.json    nl.csv     pt.json    tests.csv  tl.json\n",
      "es.csv     fr.json    it.csv     nl.json    test.csv   tests.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls nlp-course/lm-languages-data-new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {'en_df': 'en.csv',\n",
    "              'es_df': 'es.csv',\n",
    "              'fr_df': 'fr.csv',\n",
    "              'in_df': 'in.csv',\n",
    "              'it_df': 'it.csv',\n",
    "              'nl_df': 'nl.csv',\n",
    "              'pt_df': 'pt.csv',\n",
    "              'tl_df': 'tl.csv'}\n",
    "\n",
    "    \n",
    "directory = 'nlp-course/lm-languages-data-new/'    \n",
    "for (key, value) in data_files.items():\n",
    "    data_files[key] = directory + value\n",
    "    \n",
    "languages_list = list(data_files.keys())\n",
    "start_token = '↠'\n",
    "end_token = '↞'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ashyu_mT28o6"
   },
   "source": [
    "**Part 1**\n",
    "\n",
    "Write a function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. **Our token definition is a single UTF-8 encoded character**. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "xCfzsITW8Yaj"
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\"\n",
    "    data frame is table from 2 columns:\n",
    "        1. tweet id\n",
    "        2. tweet text\n",
    "    \"\"\"  \n",
    "    tokens = []\n",
    "    for path in data_files.values():\n",
    "        df = pd.read_csv(path)\n",
    "        for text in df['tweet_text'].values:\n",
    "            tokens.extend(list(text))\n",
    "    return list(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb2PGj0Yc2TY"
   },
   "source": [
    "**Part 2**\n",
    "\n",
    "Write a function lm that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant n-1 sequences, and the values are dictionaries with the n_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
    "\n",
    "{\n",
    "  \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25},\n",
    "  \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1}\n",
    "}\n",
    "\n",
    "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
    "\n",
    "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def tweets_to_text(data_file_path, n):\n",
    "    \"\"\"\n",
    "    data frame is table from 2 columns:\n",
    "        1. tweet id\n",
    "        2. tweet text\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(r''+ data_file_path)\n",
    "    tweets_list = df['tweet_text'].apply(lambda x: start_token + x + end_token).values\n",
    "    text = ''.join(tweets_list)\n",
    "    \n",
    "    text = start_token * (n-1) + text + end_token * (n-1)\n",
    "\n",
    "    return text\n",
    "\n",
    "def reorder_list(List, index_list):\n",
    "    return [List[i] for i in index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "kMC_u8eQbVvZ"
   },
   "outputs": [],
   "source": [
    "def lm(n, vocabulary, data_file_path, add_one):\n",
    "    # n - the n-gram to use (e.g., 1 - unigram, 2 - bigram, etc.)\n",
    "    # vocabulary - the vocabulary list (which you should use for calculating add_one smoothing)\n",
    "    # data_file_path - the data_file from which we record probabilities for our model\n",
    "    # add_one - True/False (use add_one smoothing or not)\n",
    "  \n",
    "    lm_dict = {}\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    text = tweets_to_text(data_file_path, n)\n",
    "\n",
    "    # Extract n length substrings\n",
    "    n_gram = [text[i: i + n] for i in range(len(text) - n)]\n",
    "\n",
    "    lm_dict = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for i_n_gram in n_gram:\n",
    "        n_1_gram = i_n_gram[0:n-1]\n",
    "        lm_dict[n_1_gram][i_n_gram[n-1]] += 1\n",
    "    \n",
    "    for key in lm_dict.keys():\n",
    "        key_count = sum(lm_dict[key].values())\n",
    "        inner_dict = {}\n",
    "        for key_1 in lm_dict[key].keys():\n",
    "            if add_one:\n",
    "                inner_dict[key_1] = (lm_dict[key][key_1] + 1) / (key_count + V)\n",
    "            else:\n",
    "                inner_dict[key_1] = lm_dict[key][key_1]/ key_count\n",
    "        if add_one:\n",
    "            lm_dict[key] = defaultdict(lambda: 1 / (key_count + V), inner_dict)\n",
    "        else:\n",
    "            lm_dict[key] = defaultdict(lambda: 0, inner_dict)\n",
    "            \n",
    "    return lm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M8TchtI22I3"
   },
   "source": [
    "**Part 3**\n",
    "\n",
    "Write a function *eval* that returns the perplexity of a model (dictionary) running over a given data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tweet(n, N, model, tweet):\n",
    "  missing_value = 1e-8\n",
    "  tweet_probabilities = []\n",
    "  \n",
    "  for i in range(N - n):\n",
    "    i_n_gram = tweet[i: i + n]\n",
    "    key = i_n_gram[0:n-1]\n",
    "    key_1 = i_n_gram[n-1]\n",
    "\n",
    "    if key in model:\n",
    "      if key_1 in model[key]:\n",
    "        tweet_probabilities.append(model[key][key_1])\n",
    "      else:\n",
    "        tweet_probabilities.append(missing_value)\n",
    "    else:\n",
    "      tweet_probabilities.append(missing_value)\n",
    "  \n",
    "  return tweet_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "5H1LVjJWniCa"
   },
   "outputs": [],
   "source": [
    "def eval(n, model, data_file):\n",
    "  # n - the n-gram that you used to build your model (must be the same number)\n",
    "  # model - the dictionary (model) to use for calculating perplexity\n",
    "  # data_file - the tweets file that you wish to calculate a perplexity score for\n",
    "  \n",
    "  df = pd.read_csv(data_file)\n",
    "  probabilities = []\n",
    "\n",
    "  for tweet in df['tweet_text'].values:\n",
    "    tweet = start_token + tweet + end_token\n",
    "    N = len(tweet)\n",
    "    tweet_probabilities = eval_tweet(n, N, model, tweet)\n",
    "    probabilities.extend(tweet_probabilities)\n",
    "    \n",
    "  entropy = -math.log2(np.mean(probabilities))\n",
    "      \n",
    "  return 2 ** entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "eZuvfwbI5aGj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.548435563954964"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = preprocess()\n",
    "n = 2\n",
    "lm_nodel = lm(n, vocabulary, data_files['en_df'], False)\n",
    "eval(n,lm_nodel, data_files['en_df'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enGmtLE3921p"
   },
   "source": [
    "**Part 4**\n",
    "\n",
    "Write a function *match* that creates a model for every relevant language, using a specific value of *n* and *add_one*. Then, calculate the perplexity of all possible pairs (e.g., en model applied on the data files en ,es, fr, in, it, nl, pt, tl; es model applied on the data files en, es...). This function should return a pandas DataFrame with columns [en ,es, fr, in, it, nl, pt, tl] and every row should be labeled with one of the languages. Then, the values are the relevant perplexity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "caAxLE9s_fvn"
   },
   "outputs": [],
   "source": [
    "def match(n, add_one, data_files):\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "    result_dict = {}\n",
    "    vocabulary = preprocess()\n",
    "    for i_language_model in languages_list:\n",
    "        \n",
    "        i_model = lm(n, vocabulary, data_files[i_language_model], add_one)\n",
    "        result_dict[i_language_model] = {}\n",
    "\n",
    "        for i_language_test in languages_list:\n",
    "            i_language_model_i_score = eval(n, i_model, data_files[i_language_test])\n",
    "            result_dict[i_language_model][i_language_test] = i_language_model_i_score\n",
    "    perlexity_df = pd.DataFrame(result_dict)\n",
    "    return perlexity_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waGMwA8H_n17"
   },
   "source": [
    "**Part 5**\n",
    "\n",
    "Run match with *n* values 1-4, once with add_one and once without, and print the 8 tables to this notebook, one after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "nk32naXyAMdl"
   },
   "outputs": [],
   "source": [
    " \n",
    "def run_match(data_files):\n",
    "\n",
    "    for n in range(1,5):\n",
    "        add_one = True\n",
    "        perlexity_df = match(n, add_one, data_files)\n",
    "        print(f'n = {n}, add_one = {add_one}')\n",
    "        display(perlexity_df)\n",
    "\n",
    "        add_one = False\n",
    "        perlexity_df = match(n, add_one, data_files)\n",
    "        print(f'n = {n}, add_one = {add_one}')\n",
    "        display(perlexity_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>22.123184</td>\n",
       "      <td>21.734873</td>\n",
       "      <td>21.950330</td>\n",
       "      <td>23.377966</td>\n",
       "      <td>22.626058</td>\n",
       "      <td>22.589962</td>\n",
       "      <td>21.898583</td>\n",
       "      <td>24.073582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>21.719854</td>\n",
       "      <td>20.354689</td>\n",
       "      <td>20.987767</td>\n",
       "      <td>22.129104</td>\n",
       "      <td>21.467562</td>\n",
       "      <td>21.883604</td>\n",
       "      <td>20.537125</td>\n",
       "      <td>22.820298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>21.959014</td>\n",
       "      <td>21.010591</td>\n",
       "      <td>21.020654</td>\n",
       "      <td>23.121476</td>\n",
       "      <td>22.109180</td>\n",
       "      <td>21.977154</td>\n",
       "      <td>21.269963</td>\n",
       "      <td>24.125203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>23.336182</td>\n",
       "      <td>22.104818</td>\n",
       "      <td>23.071022</td>\n",
       "      <td>21.130734</td>\n",
       "      <td>22.944058</td>\n",
       "      <td>23.682041</td>\n",
       "      <td>22.111354</td>\n",
       "      <td>22.145412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>22.598198</td>\n",
       "      <td>21.455954</td>\n",
       "      <td>22.073222</td>\n",
       "      <td>22.956840</td>\n",
       "      <td>21.951552</td>\n",
       "      <td>22.842744</td>\n",
       "      <td>21.611497</td>\n",
       "      <td>23.615910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>22.582835</td>\n",
       "      <td>21.891828</td>\n",
       "      <td>21.961533</td>\n",
       "      <td>23.716959</td>\n",
       "      <td>22.863691</td>\n",
       "      <td>21.925337</td>\n",
       "      <td>22.260563</td>\n",
       "      <td>24.737133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>21.812543</td>\n",
       "      <td>20.470572</td>\n",
       "      <td>21.178008</td>\n",
       "      <td>22.063923</td>\n",
       "      <td>21.553124</td>\n",
       "      <td>22.180099</td>\n",
       "      <td>20.410400</td>\n",
       "      <td>22.749803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>24.000402</td>\n",
       "      <td>22.766652</td>\n",
       "      <td>24.042356</td>\n",
       "      <td>22.117618</td>\n",
       "      <td>23.573142</td>\n",
       "      <td>24.669722</td>\n",
       "      <td>22.770099</td>\n",
       "      <td>22.617781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df  22.123184  21.734873  21.950330  23.377966  22.626058  22.589962   \n",
       "es_df  21.719854  20.354689  20.987767  22.129104  21.467562  21.883604   \n",
       "fr_df  21.959014  21.010591  21.020654  23.121476  22.109180  21.977154   \n",
       "in_df  23.336182  22.104818  23.071022  21.130734  22.944058  23.682041   \n",
       "it_df  22.598198  21.455954  22.073222  22.956840  21.951552  22.842744   \n",
       "nl_df  22.582835  21.891828  21.961533  23.716959  22.863691  21.925337   \n",
       "pt_df  21.812543  20.470572  21.178008  22.063923  21.553124  22.180099   \n",
       "tl_df  24.000402  22.766652  24.042356  22.117618  23.573142  24.669722   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  21.898583  24.073582  \n",
       "es_df  20.537125  22.820298  \n",
       "fr_df  21.269963  24.125203  \n",
       "in_df  22.111354  22.145412  \n",
       "it_df  21.611497  23.615910  \n",
       "nl_df  22.260563  24.737133  \n",
       "pt_df  20.410400  22.749803  \n",
       "tl_df  22.770099  22.617781  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>22.077733</td>\n",
       "      <td>21.687776</td>\n",
       "      <td>21.906666</td>\n",
       "      <td>23.323182</td>\n",
       "      <td>22.575065</td>\n",
       "      <td>22.542423</td>\n",
       "      <td>21.839575</td>\n",
       "      <td>24.012277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>21.675219</td>\n",
       "      <td>20.310549</td>\n",
       "      <td>20.945995</td>\n",
       "      <td>22.077205</td>\n",
       "      <td>21.419149</td>\n",
       "      <td>21.837532</td>\n",
       "      <td>20.481743</td>\n",
       "      <td>22.762143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>21.913893</td>\n",
       "      <td>20.965044</td>\n",
       "      <td>20.978818</td>\n",
       "      <td>23.067283</td>\n",
       "      <td>22.059336</td>\n",
       "      <td>21.930889</td>\n",
       "      <td>21.212628</td>\n",
       "      <td>24.063765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>23.288270</td>\n",
       "      <td>22.056929</td>\n",
       "      <td>23.025158</td>\n",
       "      <td>21.081154</td>\n",
       "      <td>22.892357</td>\n",
       "      <td>23.632234</td>\n",
       "      <td>22.051779</td>\n",
       "      <td>22.088956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>22.551781</td>\n",
       "      <td>21.409453</td>\n",
       "      <td>22.029316</td>\n",
       "      <td>22.903029</td>\n",
       "      <td>21.902061</td>\n",
       "      <td>22.794679</td>\n",
       "      <td>21.553251</td>\n",
       "      <td>23.555753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>22.536451</td>\n",
       "      <td>21.844394</td>\n",
       "      <td>21.917847</td>\n",
       "      <td>23.661391</td>\n",
       "      <td>22.812169</td>\n",
       "      <td>21.879180</td>\n",
       "      <td>22.200591</td>\n",
       "      <td>24.674162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>21.767717</td>\n",
       "      <td>20.426179</td>\n",
       "      <td>21.135860</td>\n",
       "      <td>22.012173</td>\n",
       "      <td>21.504516</td>\n",
       "      <td>22.133409</td>\n",
       "      <td>20.355356</td>\n",
       "      <td>22.691825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>23.951145</td>\n",
       "      <td>22.717347</td>\n",
       "      <td>23.994586</td>\n",
       "      <td>22.065751</td>\n",
       "      <td>23.520042</td>\n",
       "      <td>24.617867</td>\n",
       "      <td>22.708772</td>\n",
       "      <td>22.560137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df  22.077733  21.687776  21.906666  23.323182  22.575065  22.542423   \n",
       "es_df  21.675219  20.310549  20.945995  22.077205  21.419149  21.837532   \n",
       "fr_df  21.913893  20.965044  20.978818  23.067283  22.059336  21.930889   \n",
       "in_df  23.288270  22.056929  23.025158  21.081154  22.892357  23.632234   \n",
       "it_df  22.551781  21.409453  22.029316  22.903029  21.902061  22.794679   \n",
       "nl_df  22.536451  21.844394  21.917847  23.661391  22.812169  21.879180   \n",
       "pt_df  21.767717  20.426179  21.135860  22.012173  21.504516  22.133409   \n",
       "tl_df  23.951145  22.717347  23.994586  22.065751  23.520042  24.617867   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  21.839575  24.012277  \n",
       "es_df  20.481743  22.762143  \n",
       "fr_df  21.212628  24.063765  \n",
       "in_df  22.051779  22.088956  \n",
       "it_df  21.553251  23.555753  \n",
       "nl_df  22.200591  24.674162  \n",
       "pt_df  20.355356  22.691825  \n",
       "tl_df  22.708772  22.560137  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 2, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>9.986565</td>\n",
       "      <td>11.534395</td>\n",
       "      <td>11.015736</td>\n",
       "      <td>12.797388</td>\n",
       "      <td>12.193485</td>\n",
       "      <td>11.346484</td>\n",
       "      <td>12.487427</td>\n",
       "      <td>12.135492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>11.552348</td>\n",
       "      <td>8.799764</td>\n",
       "      <td>10.126377</td>\n",
       "      <td>12.324678</td>\n",
       "      <td>10.370417</td>\n",
       "      <td>11.870254</td>\n",
       "      <td>9.967664</td>\n",
       "      <td>12.029920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>11.110324</td>\n",
       "      <td>10.297592</td>\n",
       "      <td>8.973984</td>\n",
       "      <td>13.013218</td>\n",
       "      <td>11.298590</td>\n",
       "      <td>11.342957</td>\n",
       "      <td>11.209149</td>\n",
       "      <td>12.937363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>12.650569</td>\n",
       "      <td>12.509412</td>\n",
       "      <td>12.899750</td>\n",
       "      <td>10.070798</td>\n",
       "      <td>12.635099</td>\n",
       "      <td>12.474710</td>\n",
       "      <td>13.407150</td>\n",
       "      <td>11.219689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>12.191566</td>\n",
       "      <td>10.537638</td>\n",
       "      <td>11.287330</td>\n",
       "      <td>12.388867</td>\n",
       "      <td>9.521231</td>\n",
       "      <td>12.704994</td>\n",
       "      <td>11.111924</td>\n",
       "      <td>12.120910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>11.267704</td>\n",
       "      <td>11.684653</td>\n",
       "      <td>10.991838</td>\n",
       "      <td>12.333714</td>\n",
       "      <td>12.482571</td>\n",
       "      <td>9.460442</td>\n",
       "      <td>13.001361</td>\n",
       "      <td>12.875898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>12.083151</td>\n",
       "      <td>9.691988</td>\n",
       "      <td>10.737057</td>\n",
       "      <td>12.839591</td>\n",
       "      <td>10.663426</td>\n",
       "      <td>12.797785</td>\n",
       "      <td>9.202123</td>\n",
       "      <td>12.405131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>12.272254</td>\n",
       "      <td>12.309992</td>\n",
       "      <td>13.176256</td>\n",
       "      <td>11.416576</td>\n",
       "      <td>12.533692</td>\n",
       "      <td>13.138208</td>\n",
       "      <td>13.135453</td>\n",
       "      <td>9.843330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df   9.986565  11.534395  11.015736  12.797388  12.193485  11.346484   \n",
       "es_df  11.552348   8.799764  10.126377  12.324678  10.370417  11.870254   \n",
       "fr_df  11.110324  10.297592   8.973984  13.013218  11.298590  11.342957   \n",
       "in_df  12.650569  12.509412  12.899750  10.070798  12.635099  12.474710   \n",
       "it_df  12.191566  10.537638  11.287330  12.388867   9.521231  12.704994   \n",
       "nl_df  11.267704  11.684653  10.991838  12.333714  12.482571   9.460442   \n",
       "pt_df  12.083151   9.691988  10.737057  12.839591  10.663426  12.797785   \n",
       "tl_df  12.272254  12.309992  13.176256  11.416576  12.533692  13.138208   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  12.487427  12.135492  \n",
       "es_df   9.967664  12.029920  \n",
       "fr_df  11.209149  12.937363  \n",
       "in_df  13.407150  11.219689  \n",
       "it_df  11.111924  12.120910  \n",
       "nl_df  13.001361  12.875898  \n",
       "pt_df   9.202123  12.405131  \n",
       "tl_df  13.135453   9.843330  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 2, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>8.548436</td>\n",
       "      <td>9.754841</td>\n",
       "      <td>9.449275</td>\n",
       "      <td>10.692242</td>\n",
       "      <td>10.263407</td>\n",
       "      <td>9.709418</td>\n",
       "      <td>10.237033</td>\n",
       "      <td>10.062075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>9.748522</td>\n",
       "      <td>7.513592</td>\n",
       "      <td>8.709173</td>\n",
       "      <td>10.418880</td>\n",
       "      <td>8.663559</td>\n",
       "      <td>10.102434</td>\n",
       "      <td>8.368830</td>\n",
       "      <td>9.765802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>9.547273</td>\n",
       "      <td>8.624152</td>\n",
       "      <td>7.626110</td>\n",
       "      <td>10.744360</td>\n",
       "      <td>9.276329</td>\n",
       "      <td>9.501917</td>\n",
       "      <td>9.221371</td>\n",
       "      <td>10.621508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>10.777803</td>\n",
       "      <td>10.471884</td>\n",
       "      <td>10.861149</td>\n",
       "      <td>8.519882</td>\n",
       "      <td>10.586283</td>\n",
       "      <td>10.631165</td>\n",
       "      <td>10.969189</td>\n",
       "      <td>9.416480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>10.460722</td>\n",
       "      <td>8.967703</td>\n",
       "      <td>9.652551</td>\n",
       "      <td>10.410506</td>\n",
       "      <td>7.939288</td>\n",
       "      <td>10.746319</td>\n",
       "      <td>9.246221</td>\n",
       "      <td>10.064654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>9.817467</td>\n",
       "      <td>9.999700</td>\n",
       "      <td>9.525453</td>\n",
       "      <td>10.513610</td>\n",
       "      <td>10.588962</td>\n",
       "      <td>8.252249</td>\n",
       "      <td>10.771925</td>\n",
       "      <td>10.790929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>10.311505</td>\n",
       "      <td>8.277176</td>\n",
       "      <td>9.204810</td>\n",
       "      <td>10.743887</td>\n",
       "      <td>8.749456</td>\n",
       "      <td>10.694539</td>\n",
       "      <td>7.451333</td>\n",
       "      <td>9.825585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>10.439182</td>\n",
       "      <td>10.247945</td>\n",
       "      <td>10.994005</td>\n",
       "      <td>9.610464</td>\n",
       "      <td>10.388693</td>\n",
       "      <td>11.023919</td>\n",
       "      <td>10.638820</td>\n",
       "      <td>8.151938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df   8.548436   9.754841   9.449275  10.692242  10.263407   9.709418   \n",
       "es_df   9.748522   7.513592   8.709173  10.418880   8.663559  10.102434   \n",
       "fr_df   9.547273   8.624152   7.626110  10.744360   9.276329   9.501917   \n",
       "in_df  10.777803  10.471884  10.861149   8.519882  10.586283  10.631165   \n",
       "it_df  10.460722   8.967703   9.652551  10.410506   7.939288  10.746319   \n",
       "nl_df   9.817467   9.999700   9.525453  10.513610  10.588962   8.252249   \n",
       "pt_df  10.311505   8.277176   9.204810  10.743887   8.749456  10.694539   \n",
       "tl_df  10.439182  10.247945  10.994005   9.610464  10.388693  11.023919   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  10.237033  10.062075  \n",
       "es_df   8.368830   9.765802  \n",
       "fr_df   9.221371  10.621508  \n",
       "in_df  10.969189   9.416480  \n",
       "it_df   9.246221  10.064654  \n",
       "nl_df  10.771925  10.790929  \n",
       "pt_df   7.451333   9.825585  \n",
       "tl_df  10.638820   8.151938  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>7.379188</td>\n",
       "      <td>10.756152</td>\n",
       "      <td>9.696012</td>\n",
       "      <td>11.268243</td>\n",
       "      <td>10.921722</td>\n",
       "      <td>9.887505</td>\n",
       "      <td>11.786764</td>\n",
       "      <td>11.097943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>10.762831</td>\n",
       "      <td>7.212687</td>\n",
       "      <td>8.926835</td>\n",
       "      <td>11.868470</td>\n",
       "      <td>9.746611</td>\n",
       "      <td>10.968389</td>\n",
       "      <td>9.273630</td>\n",
       "      <td>12.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>9.854113</td>\n",
       "      <td>9.263584</td>\n",
       "      <td>7.005886</td>\n",
       "      <td>11.943455</td>\n",
       "      <td>10.317397</td>\n",
       "      <td>10.176139</td>\n",
       "      <td>10.738881</td>\n",
       "      <td>12.436426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>11.669429</td>\n",
       "      <td>12.131936</td>\n",
       "      <td>12.092548</td>\n",
       "      <td>8.777188</td>\n",
       "      <td>12.463657</td>\n",
       "      <td>11.609217</td>\n",
       "      <td>13.475092</td>\n",
       "      <td>11.022058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>11.156424</td>\n",
       "      <td>9.960425</td>\n",
       "      <td>10.317858</td>\n",
       "      <td>12.262880</td>\n",
       "      <td>7.994792</td>\n",
       "      <td>12.225118</td>\n",
       "      <td>11.298069</td>\n",
       "      <td>12.562298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>9.333703</td>\n",
       "      <td>10.140853</td>\n",
       "      <td>9.313059</td>\n",
       "      <td>10.700899</td>\n",
       "      <td>11.135169</td>\n",
       "      <td>7.131643</td>\n",
       "      <td>11.608194</td>\n",
       "      <td>11.513278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>11.168523</td>\n",
       "      <td>8.752595</td>\n",
       "      <td>9.874979</td>\n",
       "      <td>12.340612</td>\n",
       "      <td>10.238764</td>\n",
       "      <td>11.810045</td>\n",
       "      <td>7.947916</td>\n",
       "      <td>12.838324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>11.274558</td>\n",
       "      <td>12.642175</td>\n",
       "      <td>12.613149</td>\n",
       "      <td>10.888561</td>\n",
       "      <td>12.388844</td>\n",
       "      <td>12.102080</td>\n",
       "      <td>13.789065</td>\n",
       "      <td>8.274901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df   7.379188  10.756152   9.696012  11.268243  10.921722   9.887505   \n",
       "es_df  10.762831   7.212687   8.926835  11.868470   9.746611  10.968389   \n",
       "fr_df   9.854113   9.263584   7.005886  11.943455  10.317397  10.176139   \n",
       "in_df  11.669429  12.131936  12.092548   8.777188  12.463657  11.609217   \n",
       "it_df  11.156424   9.960425  10.317858  12.262880   7.994792  12.225118   \n",
       "nl_df   9.333703  10.140853   9.313059  10.700899  11.135169   7.131643   \n",
       "pt_df  11.168523   8.752595   9.874979  12.340612  10.238764  11.810045   \n",
       "tl_df  11.274558  12.642175  12.613149  10.888561  12.388844  12.102080   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  11.786764  11.097943  \n",
       "es_df   9.273630  12.366126  \n",
       "fr_df  10.738881  12.436426  \n",
       "in_df  13.475092  11.022058  \n",
       "it_df  11.298069  12.562298  \n",
       "nl_df  11.608194  11.513278  \n",
       "pt_df   7.947916  12.838324  \n",
       "tl_df  13.789065   8.274901  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>3.837019</td>\n",
       "      <td>5.448462</td>\n",
       "      <td>5.174504</td>\n",
       "      <td>5.447214</td>\n",
       "      <td>5.357470</td>\n",
       "      <td>5.129650</td>\n",
       "      <td>5.399947</td>\n",
       "      <td>5.033733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>5.655030</td>\n",
       "      <td>3.838306</td>\n",
       "      <td>5.107682</td>\n",
       "      <td>5.896175</td>\n",
       "      <td>5.083818</td>\n",
       "      <td>5.665561</td>\n",
       "      <td>4.762284</td>\n",
       "      <td>5.585688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>5.329020</td>\n",
       "      <td>5.120737</td>\n",
       "      <td>3.721062</td>\n",
       "      <td>5.936231</td>\n",
       "      <td>5.306061</td>\n",
       "      <td>5.245555</td>\n",
       "      <td>5.394554</td>\n",
       "      <td>5.759871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>6.261966</td>\n",
       "      <td>6.203370</td>\n",
       "      <td>6.287293</td>\n",
       "      <td>4.314009</td>\n",
       "      <td>6.251016</td>\n",
       "      <td>6.140492</td>\n",
       "      <td>6.315875</td>\n",
       "      <td>5.500943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>5.833125</td>\n",
       "      <td>5.194200</td>\n",
       "      <td>5.505782</td>\n",
       "      <td>5.915753</td>\n",
       "      <td>3.900101</td>\n",
       "      <td>6.141699</td>\n",
       "      <td>5.399402</td>\n",
       "      <td>5.663712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>5.313499</td>\n",
       "      <td>5.565887</td>\n",
       "      <td>5.274628</td>\n",
       "      <td>5.606316</td>\n",
       "      <td>5.812449</td>\n",
       "      <td>3.929465</td>\n",
       "      <td>5.767885</td>\n",
       "      <td>5.626244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>5.762523</td>\n",
       "      <td>4.767150</td>\n",
       "      <td>5.468993</td>\n",
       "      <td>5.996876</td>\n",
       "      <td>5.121950</td>\n",
       "      <td>5.935856</td>\n",
       "      <td>3.632357</td>\n",
       "      <td>5.660587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>5.802303</td>\n",
       "      <td>6.123357</td>\n",
       "      <td>6.285088</td>\n",
       "      <td>5.490860</td>\n",
       "      <td>5.630289</td>\n",
       "      <td>5.876119</td>\n",
       "      <td>5.932141</td>\n",
       "      <td>3.689011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          en_df     es_df     fr_df     in_df     it_df     nl_df     pt_df  \\\n",
       "en_df  3.837019  5.448462  5.174504  5.447214  5.357470  5.129650  5.399947   \n",
       "es_df  5.655030  3.838306  5.107682  5.896175  5.083818  5.665561  4.762284   \n",
       "fr_df  5.329020  5.120737  3.721062  5.936231  5.306061  5.245555  5.394554   \n",
       "in_df  6.261966  6.203370  6.287293  4.314009  6.251016  6.140492  6.315875   \n",
       "it_df  5.833125  5.194200  5.505782  5.915753  3.900101  6.141699  5.399402   \n",
       "nl_df  5.313499  5.565887  5.274628  5.606316  5.812449  3.929465  5.767885   \n",
       "pt_df  5.762523  4.767150  5.468993  5.996876  5.121950  5.935856  3.632357   \n",
       "tl_df  5.802303  6.123357  6.285088  5.490860  5.630289  5.876119  5.932141   \n",
       "\n",
       "          tl_df  \n",
       "en_df  5.033733  \n",
       "es_df  5.585688  \n",
       "fr_df  5.759871  \n",
       "in_df  5.500943  \n",
       "it_df  5.663712  \n",
       "nl_df  5.626244  \n",
       "pt_df  5.660587  \n",
       "tl_df  3.689011  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 4, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>10.008371</td>\n",
       "      <td>15.639750</td>\n",
       "      <td>14.236874</td>\n",
       "      <td>16.217838</td>\n",
       "      <td>15.801312</td>\n",
       "      <td>14.059858</td>\n",
       "      <td>17.227468</td>\n",
       "      <td>16.193827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>16.703953</td>\n",
       "      <td>10.386958</td>\n",
       "      <td>13.730549</td>\n",
       "      <td>18.658325</td>\n",
       "      <td>15.278917</td>\n",
       "      <td>16.069090</td>\n",
       "      <td>14.568667</td>\n",
       "      <td>19.415137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>14.971101</td>\n",
       "      <td>13.981579</td>\n",
       "      <td>9.744129</td>\n",
       "      <td>17.856657</td>\n",
       "      <td>15.766866</td>\n",
       "      <td>14.846908</td>\n",
       "      <td>16.471562</td>\n",
       "      <td>18.710176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>17.256343</td>\n",
       "      <td>18.266964</td>\n",
       "      <td>17.742980</td>\n",
       "      <td>13.182312</td>\n",
       "      <td>18.522453</td>\n",
       "      <td>17.235790</td>\n",
       "      <td>20.229874</td>\n",
       "      <td>17.771010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>17.103267</td>\n",
       "      <td>15.638883</td>\n",
       "      <td>16.112398</td>\n",
       "      <td>19.098323</td>\n",
       "      <td>11.105850</td>\n",
       "      <td>17.653397</td>\n",
       "      <td>18.086056</td>\n",
       "      <td>19.628689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>12.961353</td>\n",
       "      <td>14.030025</td>\n",
       "      <td>13.072772</td>\n",
       "      <td>14.959751</td>\n",
       "      <td>14.831056</td>\n",
       "      <td>9.436660</td>\n",
       "      <td>15.961411</td>\n",
       "      <td>15.895732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>17.231312</td>\n",
       "      <td>13.473725</td>\n",
       "      <td>15.309776</td>\n",
       "      <td>19.254112</td>\n",
       "      <td>16.256408</td>\n",
       "      <td>17.468112</td>\n",
       "      <td>11.953943</td>\n",
       "      <td>19.736619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>17.361038</td>\n",
       "      <td>19.342445</td>\n",
       "      <td>18.867909</td>\n",
       "      <td>17.547877</td>\n",
       "      <td>18.718018</td>\n",
       "      <td>18.026929</td>\n",
       "      <td>20.806928</td>\n",
       "      <td>11.748046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df  10.008371  15.639750  14.236874  16.217838  15.801312  14.059858   \n",
       "es_df  16.703953  10.386958  13.730549  18.658325  15.278917  16.069090   \n",
       "fr_df  14.971101  13.981579   9.744129  17.856657  15.766866  14.846908   \n",
       "in_df  17.256343  18.266964  17.742980  13.182312  18.522453  17.235790   \n",
       "it_df  17.103267  15.638883  16.112398  19.098323  11.105850  17.653397   \n",
       "nl_df  12.961353  14.030025  13.072772  14.959751  14.831056   9.436660   \n",
       "pt_df  17.231312  13.473725  15.309776  19.254112  16.256408  17.468112   \n",
       "tl_df  17.361038  19.342445  18.867909  17.547877  18.718018  18.026929   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  17.227468  16.193827  \n",
       "es_df  14.568667  19.415137  \n",
       "fr_df  16.471562  18.710176  \n",
       "in_df  20.229874  17.771010  \n",
       "it_df  18.086056  19.628689  \n",
       "nl_df  15.961411  15.895732  \n",
       "pt_df  11.953943  19.736619  \n",
       "tl_df  20.806928  11.748046  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dict = run_match(data_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cg4h5Cl0q2nR"
   },
   "source": [
    "**Part 6**\n",
    "\n",
    "Each line in the file test.csv contains a sentence and the language it belongs to. Write a function that uses your language models to classify the correct language of each sentence.\n",
    "\n",
    "Important note regarding the grading of this section: this is an open question, where a different solution will yield different accuracy scores. any solution that is not trivial (e.g. returning 'en' in all cases) will be excepted. We do reserve the right to give bonus points to exceptionally good/creative solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls nlp-course/lm-languages-data-new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'nlp-course/lm-languages-data-new/'\n",
    "test_csv_files =  glob.glob(test_folder + '/*.csv')\n",
    "test_files =  {}\n",
    "for i_file in test_csv_files:\n",
    "    file_name_with_ending = os.path.basename(i_file)\n",
    "    file_name = os.path.splitext(file_name_with_ending)[0]\n",
    "    test_files[file_name + '_df'] = f'' + i_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_test(n, data_file_path, add_one):\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "\n",
    "    senstences_list = pd.read_csv(data_file_path)['tweet_text'].to_list()\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    for i_language_model in languages_list:\n",
    "        result_dict[i_language_model] = {}\n",
    "        i_model = lm(n, vocabulary, data_files[i_language_model], add_one)\n",
    "\n",
    "        for i_test_senstence_idx in range(len(senstences_list)):\n",
    "            i_test_senstence = senstences_list[i_test_senstence_idx]\n",
    "\n",
    "            sentence_probabilities = eval_tweet(n, len(i_test_senstence), i_model, i_test_senstence)\n",
    "            entropy = -math.log2(np.mean(sentence_probabilities))\n",
    "            i_sentence_model_i_score = 2 ** entropy\n",
    "\n",
    "            result_dict[i_language_model][i_test_senstence_idx] = i_sentence_model_i_score\n",
    "\n",
    "    perlexity_df = pd.DataFrame(result_dict)\n",
    "    display(perlexity_df)\n",
    "    perlexity_array = perlexity_df.to_numpy()\n",
    "    language_match_index = np.argmin(perlexity_array, axis=1)\n",
    "    language_match_list = reorder_list(languages_list, language_match_index)\n",
    "    perlexity_df['predict'] = language_match_index\n",
    "    perlexity_df['predict_language'] = language_match_list\n",
    "    display(perlexity_df)\n",
    "\n",
    "    return perlexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD6IRIQLrlZF"
   },
   "outputs": [],
   "source": [
    "def classify(n, data_file_path, add_one):\n",
    "    match_dict  = match_test(n, data_file_path, add_one)\n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "test_path = test_folder + 'test.csv'\n",
    "clasification_result = classify(2, test_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_csv(test_path).get('label').to_list()\n",
    "y_true = list(map(lambda x: languages_list.index(x+'_df'),y_true))\n",
    "y_pred = clasification_result['predict'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5ECmLd3rktZ"
   },
   "source": [
    "**Part 7**\n",
    "\n",
    "Calculate the F1 score of your output from part 6. (hint: you can use https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOBO3YQls66r"
   },
   "outputs": [],
   "source": [
    "def calc_f1(y_true,y_pred ):\n",
    "    return np.round(f1_score(y_true, y_pred,average=\"micro\"),3)\n",
    "f_score_result = calc_f1(y_true,y_pred)\n",
    "print('The F-score we acheive is ' + str(f_score_result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEtckSWNANqW"
   },
   "source": [
    "# **Good luck!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
