{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ce5pQK3bFn_"
   },
   "source": [
    "# Assignment 1\n",
    "In this assignment you will be creating tools for learning and testing language models.\n",
    "The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwG8v-Ll49KM"
   },
   "source": [
    "*As a preparation for this task, download the data files from the course git repository.\n",
    "\n",
    "The relevant files are under **lm-languages-data-new**:\n",
    "\n",
    "\n",
    "*   en.csv (or the equivalent JSON file)\n",
    "*   es.csv (or the equivalent JSON file)\n",
    "*   fr.csv (or the equivalent JSON file)\n",
    "*   in.csv (or the equivalent JSON file)\n",
    "*   it.csv (or the equivalent JSON file)\n",
    "*   nl.csv (or the equivalent JSON file)\n",
    "*   pt.csv (or the equivalent JSON file)\n",
    "*   tl.csv (or the equivalent JSON file)\n",
    "*   test.csv (or the equivalent JSON file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import time\n",
    "import glob\n",
    "import os \n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xC-87z2GWMq",
    "outputId": "7b7f40be-bf9b-4d6c-da81-25d60d710a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nlp-course' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kfirbar/nlp-course.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOVb4IhsqimJ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Important note: please use only the files under lm-languages-data-new and NOT under lm-languages-data**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYdhPfbAGkip",
    "outputId": "af6566c6-e6e6-409a-c569-8fab9bdf400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en.csv     es.json    in.csv     it.json    pt.csv     test.json  tl.csv\n",
      "en.json    fr.csv     in.json    nl.csv     pt.json    tests.csv  tl.json\n",
      "es.csv     fr.json    it.csv     nl.json    test.csv   tests.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls nlp-course/lm-languages-data-new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {'en_df': 'en.csv',\n",
    "              'es_df': 'es.csv',\n",
    "              'fr_df': 'fr.csv',\n",
    "              'in_df': 'in.csv',\n",
    "              'it_df': 'it.csv',\n",
    "              'nl_df': 'nl.csv',\n",
    "              'pt_df': 'pt.csv',\n",
    "              'tl_df': 'tl.csv'}\n",
    "\n",
    "    \n",
    "directory = 'nlp-course/lm-languages-data-new/'    \n",
    "for (key, value) in data_files.items():\n",
    "    data_files[key] = directory + value\n",
    "    \n",
    "languages_list = list(data_files.keys())\n",
    "start_token = '↠'\n",
    "end_token = '↞'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ashyu_mT28o6"
   },
   "source": [
    "**Part 1**\n",
    "\n",
    "Write a function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. **Our token definition is a single UTF-8 encoded character**. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xCfzsITW8Yaj"
   },
   "outputs": [],
   "source": [
    "def preprocess(data_files):\n",
    "    \"\"\"\n",
    "    data frame is table from 2 columns:\n",
    "        1. tweet id\n",
    "        2. tweet text\n",
    "    \"\"\"  \n",
    "    tokens = []\n",
    "    for path in data_files.values():\n",
    "        df = pd.read_csv(path)\n",
    "        if tokens.__len__() == 0 :\n",
    "            columns_list = df.columns.to_list()\n",
    "        for text in df[columns_list[-1]].values:\n",
    "            tokens.extend(list(text))\n",
    "    return list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = preprocess(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb2PGj0Yc2TY"
   },
   "source": [
    "**Part 2**\n",
    "\n",
    "Write a function lm that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant n-1 sequences, and the values are dictionaries with the n_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
    "\n",
    "{\n",
    "  \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25},\n",
    "  \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1}\n",
    "}\n",
    "\n",
    "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
    "\n",
    "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "def tweets_to_text(data_file_path, n):\n",
    "    \"\"\"\n",
    "    data frame is table from 2 columns:\n",
    "        1. tweet id\n",
    "        2. tweet text\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(r''+ data_file_path)\n",
    "    debug = True\n",
    "    if debug == True:\n",
    "        df = df[0:100]\n",
    "    columns_list = df.columns.to_list()\n",
    "    tweets_list = df[columns_list[-1]].apply(lambda x: start_token + x + end_token).values\n",
    "    text = ''.join(tweets_list)\n",
    "    \n",
    "    text = start_token * (n-1) + text + end_token * (n-1)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kMC_u8eQbVvZ"
   },
   "outputs": [],
   "source": [
    "def lm(n, vocabulary, data_file_path, add_one):\n",
    "    # n - the n-gram to use (e.g., 1 - unigram, 2 - bigram, etc.)\n",
    "    # vocabulary - the vocabulary list (which you should use for calculating add_one smoothing)\n",
    "    # data_file_path - the data_file from which we record probabilities for our model\n",
    "    # add_one - True/False (use add_one smoothing or not)\n",
    "  \n",
    "    lm_dict = {}\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    text = tweets_to_text(data_file_path, n)\n",
    "\n",
    "    # Extract n - 1 length substrings\n",
    "    n_1_gram = [text[i: i + n-1] for i in range(len(text) - (n-1))]\n",
    "    counter_obj_n_1_gram = dict(Counter(n_1_gram))\n",
    "\n",
    "    # Extract n length substrings\n",
    "    n_gram = [text[i: i + n] for i in range(len(text) - n)]\n",
    "    counter_obj_n_gram = dict(Counter(n_gram))\n",
    "\n",
    "    for key in counter_obj_n_1_gram.keys():\n",
    "        inner_dict = {}\n",
    "        if add_one:\n",
    "            gen = (key_1 for key_1 in counter_obj_n_gram.keys() if key_1[0:n-1] == key)\n",
    "            for key_1 in gen:\n",
    "                val = (int(counter_obj_n_gram[key_1]) + 1) / (int(counter_obj_n_1_gram[key]) + V)\n",
    "                inner_dict[key_1[-1]] = val\n",
    "\n",
    "            gen = (token for token in vocabulary if not(token in inner_dict))\n",
    "            for key_1 in gen:\n",
    "                val = 1 /  (int(counter_obj_n_1_gram[key]) + V)\n",
    "                inner_dict[key_1[-1]] = val\n",
    "\n",
    "        else:\n",
    "            gen = (key_1 for key_1 in counter_obj_n_gram.keys() if key_1[0:n-1] == key)\n",
    "            sum_vals = 0\n",
    "            for key_1 in gen:\n",
    "                val = int(counter_obj_n_gram[key_1]) / int(counter_obj_n_1_gram[key])\n",
    "                inner_dict[key_1[-1]] = val\n",
    "                sum_vals += val\n",
    "\n",
    "        lm_dict[key] = inner_dict.copy()\n",
    "\n",
    "    return lm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lm = lm(2, vocabulary, data_files['en_df'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M8TchtI22I3"
   },
   "source": [
    "**Part 3**\n",
    "\n",
    "Write a function *eval* that returns the perplexity of a model (dictionary) running over a given data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "F0kkMn328-lJ"
   },
   "outputs": [],
   "source": [
    "def eval(n, model, data_file):\n",
    "    # n - the n-gram that you used to build your model (must be the same number)\n",
    "    # model - the dictionary (model) to use for calculating perplexity\n",
    "    # data_file - the tweets file that you wish to claculate a perplexity score for\n",
    "\n",
    "    # read file\n",
    "    if os.path.exists(data_file):\n",
    "        text = tweets_to_text(data_file, n)\n",
    "    else:\n",
    "        text = data_file\n",
    "    # Extract n length substrings\n",
    "    n_gram = [text[i: i + n] for i in range(len(text) - n)]\n",
    "\n",
    "    model_keys = model.keys()\n",
    "    entropy = 0 \n",
    "    for i_letter in n_gram:\n",
    "        if i_letter[0:n-1] in model_keys: \n",
    "            i_letter_model = model[i_letter[0:n-1]]\n",
    "            if i_letter[n-1] in i_letter_model.keys():\n",
    "                second_letter_prob = i_letter_model[i_letter[n-1]]\n",
    "                entropy += -np.log2(second_letter_prob)\n",
    "            else:\n",
    "                entropy += 0\n",
    "        else:\n",
    "            entropy += 0\n",
    "    entropy = entropy/len(n_gram)\n",
    "    perplexity_score = 2**(entropy)\n",
    "    return perplexity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.384868998083354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(2, test_lm, data_files['en_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enGmtLE3921p"
   },
   "source": [
    "**Part 4**\n",
    "\n",
    "Write a function *match* that creates a model for every relevant language, using a specific value of *n* and *add_one*. Then, calculate the perplexity of all possible pairs (e.g., en model applied on the data files en ,es, fr, in, it, nl, pt, tl; es model applied on the data files en, es...). This function should return a pandas DataFrame with columns [en ,es, fr, in, it, nl, pt, tl] and every row should be labeled with one of the languages. Then, the values are the relevant perplexity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "caAxLE9s_fvn"
   },
   "outputs": [],
   "source": [
    "def match(n, add_one, data_files):\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "    result_dict = {}\n",
    "    vocabulary = preprocess(data_files)\n",
    "    for i_language_model in languages_list:\n",
    "        \n",
    "        i_model = lm(n, vocabulary, data_files[i_language_model], add_one)\n",
    "        result_dict[i_language_model] = {}\n",
    "\n",
    "        for i_language_test in languages_list:\n",
    "            i_language_model_i_score = eval(n, i_model, data_files[i_language_test])\n",
    "            result_dict[i_language_model][i_language_test] = i_language_model_i_score\n",
    "    perlexity_df = pd.DataFrame(result_dict)\n",
    "    return perlexity_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waGMwA8H_n17"
   },
   "source": [
    "**Part 5**\n",
    "\n",
    "Run match with *n* values 1-4, once with add_one and once without, and print the 8 tables to this notebook, one after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nk32naXyAMdl"
   },
   "outputs": [],
   "source": [
    " \n",
    "def run_match(data_files):\n",
    "    full_model_dict = {}\n",
    "    # for n in range(2,3):\n",
    "\n",
    "    for n in range(1,5):\n",
    "        add_one = True\n",
    "        perlexity_df = match(n, add_one, data_files)\n",
    "        print(f'n = {n}, add_one = {add_one}')\n",
    "        display(perlexity_df)\n",
    "\n",
    "        add_one = False\n",
    "        perlexity_df = match(n, add_one, data_files)\n",
    "        print(f'n = {n}, add_one = {add_one}')\n",
    "        display(perlexity_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = True) model perlexity score per model and test language :\n",
      "\n",
      "n = 1, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>45.655970</td>\n",
       "      <td>51.355402</td>\n",
       "      <td>49.301698</td>\n",
       "      <td>51.440155</td>\n",
       "      <td>51.115690</td>\n",
       "      <td>49.920505</td>\n",
       "      <td>53.720380</td>\n",
       "      <td>52.128620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>45.452144</td>\n",
       "      <td>41.505010</td>\n",
       "      <td>43.749825</td>\n",
       "      <td>48.909240</td>\n",
       "      <td>44.327461</td>\n",
       "      <td>46.477788</td>\n",
       "      <td>45.430218</td>\n",
       "      <td>50.887953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>47.074058</td>\n",
       "      <td>46.360269</td>\n",
       "      <td>42.557872</td>\n",
       "      <td>51.742064</td>\n",
       "      <td>46.095812</td>\n",
       "      <td>47.880026</td>\n",
       "      <td>49.104143</td>\n",
       "      <td>54.361214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>47.102662</td>\n",
       "      <td>51.615250</td>\n",
       "      <td>49.987591</td>\n",
       "      <td>42.887313</td>\n",
       "      <td>51.716640</td>\n",
       "      <td>48.165780</td>\n",
       "      <td>51.151363</td>\n",
       "      <td>47.356540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>42.277777</td>\n",
       "      <td>41.678911</td>\n",
       "      <td>40.670809</td>\n",
       "      <td>45.966293</td>\n",
       "      <td>38.971338</td>\n",
       "      <td>43.101557</td>\n",
       "      <td>43.918374</td>\n",
       "      <td>47.100703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>44.844935</td>\n",
       "      <td>47.609415</td>\n",
       "      <td>45.624331</td>\n",
       "      <td>48.050698</td>\n",
       "      <td>47.293902</td>\n",
       "      <td>42.118229</td>\n",
       "      <td>49.341800</td>\n",
       "      <td>50.380296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>49.205830</td>\n",
       "      <td>47.269991</td>\n",
       "      <td>47.924765</td>\n",
       "      <td>51.674580</td>\n",
       "      <td>48.308706</td>\n",
       "      <td>50.512218</td>\n",
       "      <td>46.461623</td>\n",
       "      <td>53.818373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>54.486198</td>\n",
       "      <td>60.875533</td>\n",
       "      <td>59.630634</td>\n",
       "      <td>54.425462</td>\n",
       "      <td>60.540051</td>\n",
       "      <td>58.100922</td>\n",
       "      <td>61.147729</td>\n",
       "      <td>50.515084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df  45.655970  51.355402  49.301698  51.440155  51.115690  49.920505   \n",
       "es_df  45.452144  41.505010  43.749825  48.909240  44.327461  46.477788   \n",
       "fr_df  47.074058  46.360269  42.557872  51.742064  46.095812  47.880026   \n",
       "in_df  47.102662  51.615250  49.987591  42.887313  51.716640  48.165780   \n",
       "it_df  42.277777  41.678911  40.670809  45.966293  38.971338  43.101557   \n",
       "nl_df  44.844935  47.609415  45.624331  48.050698  47.293902  42.118229   \n",
       "pt_df  49.205830  47.269991  47.924765  51.674580  48.308706  50.512218   \n",
       "tl_df  54.486198  60.875533  59.630634  54.425462  60.540051  58.100922   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  53.720380  52.128620  \n",
       "es_df  45.430218  50.887953  \n",
       "fr_df  49.104143  54.361214  \n",
       "in_df  51.151363  47.356540  \n",
       "it_df  43.918374  47.100703  \n",
       "nl_df  49.341800  50.380296  \n",
       "pt_df  46.461623  53.818373  \n",
       "tl_df  61.147729  50.515084  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = False) model perlexity score per model and test language :\n",
      "\n",
      "n = 1, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>38.961941</td>\n",
       "      <td>41.929366</td>\n",
       "      <td>41.182271</td>\n",
       "      <td>41.709666</td>\n",
       "      <td>41.382011</td>\n",
       "      <td>39.933839</td>\n",
       "      <td>41.636759</td>\n",
       "      <td>41.436843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>32.378747</td>\n",
       "      <td>35.103377</td>\n",
       "      <td>32.358444</td>\n",
       "      <td>35.586874</td>\n",
       "      <td>32.755420</td>\n",
       "      <td>33.675336</td>\n",
       "      <td>33.921399</td>\n",
       "      <td>36.349828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>34.076984</td>\n",
       "      <td>35.586083</td>\n",
       "      <td>36.546817</td>\n",
       "      <td>36.641208</td>\n",
       "      <td>36.828866</td>\n",
       "      <td>36.481139</td>\n",
       "      <td>37.387258</td>\n",
       "      <td>38.103698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>39.555033</td>\n",
       "      <td>43.216252</td>\n",
       "      <td>42.287237</td>\n",
       "      <td>35.934859</td>\n",
       "      <td>42.984583</td>\n",
       "      <td>39.194853</td>\n",
       "      <td>40.588367</td>\n",
       "      <td>38.645186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>33.223687</td>\n",
       "      <td>32.306595</td>\n",
       "      <td>33.487553</td>\n",
       "      <td>35.651692</td>\n",
       "      <td>32.916407</td>\n",
       "      <td>32.559039</td>\n",
       "      <td>33.075585</td>\n",
       "      <td>36.029886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>36.962915</td>\n",
       "      <td>39.409093</td>\n",
       "      <td>38.215480</td>\n",
       "      <td>39.072086</td>\n",
       "      <td>38.859453</td>\n",
       "      <td>35.447688</td>\n",
       "      <td>38.964376</td>\n",
       "      <td>40.482297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>33.551902</td>\n",
       "      <td>34.022261</td>\n",
       "      <td>34.305865</td>\n",
       "      <td>34.794524</td>\n",
       "      <td>33.862799</td>\n",
       "      <td>34.415740</td>\n",
       "      <td>37.718362</td>\n",
       "      <td>35.935042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>42.294933</td>\n",
       "      <td>47.535579</td>\n",
       "      <td>48.735527</td>\n",
       "      <td>42.006983</td>\n",
       "      <td>46.523005</td>\n",
       "      <td>44.918698</td>\n",
       "      <td>45.372337</td>\n",
       "      <td>41.860766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df  38.961941  41.929366  41.182271  41.709666  41.382011  39.933839   \n",
       "es_df  32.378747  35.103377  32.358444  35.586874  32.755420  33.675336   \n",
       "fr_df  34.076984  35.586083  36.546817  36.641208  36.828866  36.481139   \n",
       "in_df  39.555033  43.216252  42.287237  35.934859  42.984583  39.194853   \n",
       "it_df  33.223687  32.306595  33.487553  35.651692  32.916407  32.559039   \n",
       "nl_df  36.962915  39.409093  38.215480  39.072086  38.859453  35.447688   \n",
       "pt_df  33.551902  34.022261  34.305865  34.794524  33.862799  34.415740   \n",
       "tl_df  42.294933  47.535579  48.735527  42.006983  46.523005  44.918698   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  41.636759  41.436843  \n",
       "es_df  33.921399  36.349828  \n",
       "fr_df  37.387258  38.103698  \n",
       "in_df  40.588367  38.645186  \n",
       "it_df  33.075585  36.029886  \n",
       "nl_df  38.964376  40.482297  \n",
       "pt_df  37.718362  35.935042  \n",
       "tl_df  45.372337  41.860766  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = True) model perlexity score per model and test language :\n",
      "\n",
      "n = 2, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>109.633495</td>\n",
       "      <td>181.131325</td>\n",
       "      <td>155.932843</td>\n",
       "      <td>183.448419</td>\n",
       "      <td>185.085043</td>\n",
       "      <td>159.789446</td>\n",
       "      <td>214.788732</td>\n",
       "      <td>187.363344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>121.855617</td>\n",
       "      <td>93.759347</td>\n",
       "      <td>108.233732</td>\n",
       "      <td>153.050915</td>\n",
       "      <td>111.004566</td>\n",
       "      <td>141.541569</td>\n",
       "      <td>133.414088</td>\n",
       "      <td>160.746126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>126.343186</td>\n",
       "      <td>135.200848</td>\n",
       "      <td>96.370419</td>\n",
       "      <td>162.231691</td>\n",
       "      <td>144.966340</td>\n",
       "      <td>150.794636</td>\n",
       "      <td>167.382475</td>\n",
       "      <td>180.972235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>165.223403</td>\n",
       "      <td>201.519532</td>\n",
       "      <td>178.059431</td>\n",
       "      <td>110.181932</td>\n",
       "      <td>194.132097</td>\n",
       "      <td>180.279689</td>\n",
       "      <td>222.129794</td>\n",
       "      <td>166.135812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>130.095771</td>\n",
       "      <td>111.620035</td>\n",
       "      <td>118.491223</td>\n",
       "      <td>150.769573</td>\n",
       "      <td>89.437790</td>\n",
       "      <td>147.181633</td>\n",
       "      <td>139.513553</td>\n",
       "      <td>160.444998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>138.232860</td>\n",
       "      <td>168.466015</td>\n",
       "      <td>148.679664</td>\n",
       "      <td>172.825315</td>\n",
       "      <td>173.977410</td>\n",
       "      <td>100.392034</td>\n",
       "      <td>203.460108</td>\n",
       "      <td>195.201295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>131.383824</td>\n",
       "      <td>118.845906</td>\n",
       "      <td>121.535194</td>\n",
       "      <td>155.585820</td>\n",
       "      <td>122.953341</td>\n",
       "      <td>151.442675</td>\n",
       "      <td>119.244500</td>\n",
       "      <td>167.316105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>152.813515</td>\n",
       "      <td>189.549481</td>\n",
       "      <td>183.233925</td>\n",
       "      <td>152.710602</td>\n",
       "      <td>188.030566</td>\n",
       "      <td>185.343554</td>\n",
       "      <td>219.696342</td>\n",
       "      <td>107.270217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            en_df       es_df       fr_df       in_df       it_df       nl_df  \\\n",
       "en_df  109.633495  181.131325  155.932843  183.448419  185.085043  159.789446   \n",
       "es_df  121.855617   93.759347  108.233732  153.050915  111.004566  141.541569   \n",
       "fr_df  126.343186  135.200848   96.370419  162.231691  144.966340  150.794636   \n",
       "in_df  165.223403  201.519532  178.059431  110.181932  194.132097  180.279689   \n",
       "it_df  130.095771  111.620035  118.491223  150.769573   89.437790  147.181633   \n",
       "nl_df  138.232860  168.466015  148.679664  172.825315  173.977410  100.392034   \n",
       "pt_df  131.383824  118.845906  121.535194  155.585820  122.953341  151.442675   \n",
       "tl_df  152.813515  189.549481  183.233925  152.710602  188.030566  185.343554   \n",
       "\n",
       "            pt_df       tl_df  \n",
       "en_df  214.788732  187.363344  \n",
       "es_df  133.414088  160.746126  \n",
       "fr_df  167.382475  180.972235  \n",
       "in_df  222.129794  166.135812  \n",
       "it_df  139.513553  160.444998  \n",
       "nl_df  203.460108  195.201295  \n",
       "pt_df  119.244500  167.316105  \n",
       "tl_df  219.696342  107.270217  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = False) model perlexity score per model and test language :\n",
      "\n",
      "n = 2, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>14.384869</td>\n",
       "      <td>11.956690</td>\n",
       "      <td>11.489436</td>\n",
       "      <td>12.446335</td>\n",
       "      <td>11.198522</td>\n",
       "      <td>11.131667</td>\n",
       "      <td>10.326200</td>\n",
       "      <td>11.379106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>11.352011</td>\n",
       "      <td>12.466218</td>\n",
       "      <td>10.157946</td>\n",
       "      <td>11.581361</td>\n",
       "      <td>9.497516</td>\n",
       "      <td>11.577911</td>\n",
       "      <td>8.991426</td>\n",
       "      <td>10.879584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>10.489021</td>\n",
       "      <td>9.993651</td>\n",
       "      <td>13.608300</td>\n",
       "      <td>11.084216</td>\n",
       "      <td>10.198140</td>\n",
       "      <td>10.824662</td>\n",
       "      <td>9.544355</td>\n",
       "      <td>10.648533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>13.198092</td>\n",
       "      <td>11.261706</td>\n",
       "      <td>12.992268</td>\n",
       "      <td>14.073481</td>\n",
       "      <td>10.208837</td>\n",
       "      <td>12.167447</td>\n",
       "      <td>10.484984</td>\n",
       "      <td>10.769811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>12.429877</td>\n",
       "      <td>10.339403</td>\n",
       "      <td>11.545752</td>\n",
       "      <td>11.940116</td>\n",
       "      <td>12.511038</td>\n",
       "      <td>13.345853</td>\n",
       "      <td>9.897333</td>\n",
       "      <td>10.937212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>10.348992</td>\n",
       "      <td>11.064295</td>\n",
       "      <td>11.793545</td>\n",
       "      <td>12.204031</td>\n",
       "      <td>10.067780</td>\n",
       "      <td>13.240227</td>\n",
       "      <td>10.402905</td>\n",
       "      <td>10.892198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>10.882331</td>\n",
       "      <td>9.260273</td>\n",
       "      <td>10.726620</td>\n",
       "      <td>11.076520</td>\n",
       "      <td>9.593008</td>\n",
       "      <td>11.912083</td>\n",
       "      <td>12.351687</td>\n",
       "      <td>10.090859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>10.797583</td>\n",
       "      <td>9.587003</td>\n",
       "      <td>10.587205</td>\n",
       "      <td>9.161233</td>\n",
       "      <td>8.899691</td>\n",
       "      <td>9.953089</td>\n",
       "      <td>8.478238</td>\n",
       "      <td>11.231359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en_df      es_df      fr_df      in_df      it_df      nl_df  \\\n",
       "en_df  14.384869  11.956690  11.489436  12.446335  11.198522  11.131667   \n",
       "es_df  11.352011  12.466218  10.157946  11.581361   9.497516  11.577911   \n",
       "fr_df  10.489021   9.993651  13.608300  11.084216  10.198140  10.824662   \n",
       "in_df  13.198092  11.261706  12.992268  14.073481  10.208837  12.167447   \n",
       "it_df  12.429877  10.339403  11.545752  11.940116  12.511038  13.345853   \n",
       "nl_df  10.348992  11.064295  11.793545  12.204031  10.067780  13.240227   \n",
       "pt_df  10.882331   9.260273  10.726620  11.076520   9.593008  11.912083   \n",
       "tl_df  10.797583   9.587003  10.587205   9.161233   8.899691   9.953089   \n",
       "\n",
       "           pt_df      tl_df  \n",
       "en_df  10.326200  11.379106  \n",
       "es_df   8.991426  10.879584  \n",
       "fr_df   9.544355  10.648533  \n",
       "in_df  10.484984  10.769811  \n",
       "it_df   9.897333  10.937212  \n",
       "nl_df  10.402905  10.892198  \n",
       "pt_df  12.351687  10.090859  \n",
       "tl_df   8.478238  11.231359  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = True) model perlexity score per model and test language :\n",
      "\n",
      "n = 3, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>321.999134</td>\n",
       "      <td>236.257631</td>\n",
       "      <td>229.498439</td>\n",
       "      <td>281.940520</td>\n",
       "      <td>210.894365</td>\n",
       "      <td>238.569239</td>\n",
       "      <td>212.671714</td>\n",
       "      <td>254.329931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>257.503523</td>\n",
       "      <td>284.599391</td>\n",
       "      <td>203.186930</td>\n",
       "      <td>261.580541</td>\n",
       "      <td>198.084039</td>\n",
       "      <td>253.449131</td>\n",
       "      <td>208.616890</td>\n",
       "      <td>252.958853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>211.403993</td>\n",
       "      <td>190.618387</td>\n",
       "      <td>289.206439</td>\n",
       "      <td>235.974703</td>\n",
       "      <td>206.352018</td>\n",
       "      <td>221.004280</td>\n",
       "      <td>209.730663</td>\n",
       "      <td>219.068264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>311.233221</td>\n",
       "      <td>209.911281</td>\n",
       "      <td>278.125045</td>\n",
       "      <td>347.350680</td>\n",
       "      <td>199.303286</td>\n",
       "      <td>262.739773</td>\n",
       "      <td>218.587319</td>\n",
       "      <td>245.690487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>293.942131</td>\n",
       "      <td>236.535125</td>\n",
       "      <td>268.311651</td>\n",
       "      <td>293.160808</td>\n",
       "      <td>295.176144</td>\n",
       "      <td>323.448686</td>\n",
       "      <td>253.976038</td>\n",
       "      <td>263.701585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>226.377940</td>\n",
       "      <td>215.751858</td>\n",
       "      <td>240.925609</td>\n",
       "      <td>276.411546</td>\n",
       "      <td>199.172320</td>\n",
       "      <td>304.514289</td>\n",
       "      <td>223.796944</td>\n",
       "      <td>239.133309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>225.257646</td>\n",
       "      <td>177.602952</td>\n",
       "      <td>213.803449</td>\n",
       "      <td>229.021473</td>\n",
       "      <td>193.385723</td>\n",
       "      <td>248.667676</td>\n",
       "      <td>334.587154</td>\n",
       "      <td>208.026460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>215.040469</td>\n",
       "      <td>161.169274</td>\n",
       "      <td>180.047655</td>\n",
       "      <td>170.490070</td>\n",
       "      <td>145.514891</td>\n",
       "      <td>180.763809</td>\n",
       "      <td>139.857577</td>\n",
       "      <td>248.014005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            en_df       es_df       fr_df       in_df       it_df       nl_df  \\\n",
       "en_df  321.999134  236.257631  229.498439  281.940520  210.894365  238.569239   \n",
       "es_df  257.503523  284.599391  203.186930  261.580541  198.084039  253.449131   \n",
       "fr_df  211.403993  190.618387  289.206439  235.974703  206.352018  221.004280   \n",
       "in_df  311.233221  209.911281  278.125045  347.350680  199.303286  262.739773   \n",
       "it_df  293.942131  236.535125  268.311651  293.160808  295.176144  323.448686   \n",
       "nl_df  226.377940  215.751858  240.925609  276.411546  199.172320  304.514289   \n",
       "pt_df  225.257646  177.602952  213.803449  229.021473  193.385723  248.667676   \n",
       "tl_df  215.040469  161.169274  180.047655  170.490070  145.514891  180.763809   \n",
       "\n",
       "            pt_df       tl_df  \n",
       "en_df  212.671714  254.329931  \n",
       "es_df  208.616890  252.958853  \n",
       "fr_df  209.730663  219.068264  \n",
       "in_df  218.587319  245.690487  \n",
       "it_df  253.976038  263.701585  \n",
       "nl_df  223.796944  239.133309  \n",
       "pt_df  334.587154  208.026460  \n",
       "tl_df  139.857577  248.014005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = False) model perlexity score per model and test language :\n",
      "\n",
      "n = 3, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>4.309184</td>\n",
       "      <td>2.293770</td>\n",
       "      <td>2.532178</td>\n",
       "      <td>2.231851</td>\n",
       "      <td>2.123328</td>\n",
       "      <td>2.529614</td>\n",
       "      <td>1.927856</td>\n",
       "      <td>2.091247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>2.764492</td>\n",
       "      <td>4.392235</td>\n",
       "      <td>2.970475</td>\n",
       "      <td>2.393427</td>\n",
       "      <td>3.016536</td>\n",
       "      <td>2.456670</td>\n",
       "      <td>2.744862</td>\n",
       "      <td>2.151533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>2.742375</td>\n",
       "      <td>2.544285</td>\n",
       "      <td>4.415564</td>\n",
       "      <td>2.285090</td>\n",
       "      <td>2.548024</td>\n",
       "      <td>2.547205</td>\n",
       "      <td>2.349252</td>\n",
       "      <td>1.930364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>2.373589</td>\n",
       "      <td>2.222998</td>\n",
       "      <td>2.429772</td>\n",
       "      <td>4.638793</td>\n",
       "      <td>2.267839</td>\n",
       "      <td>2.205126</td>\n",
       "      <td>2.006026</td>\n",
       "      <td>2.193134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>2.897508</td>\n",
       "      <td>3.137128</td>\n",
       "      <td>3.166326</td>\n",
       "      <td>2.543176</td>\n",
       "      <td>4.805001</td>\n",
       "      <td>2.564129</td>\n",
       "      <td>2.826795</td>\n",
       "      <td>2.290382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>2.639346</td>\n",
       "      <td>2.318133</td>\n",
       "      <td>2.448077</td>\n",
       "      <td>2.224871</td>\n",
       "      <td>2.323701</td>\n",
       "      <td>4.408137</td>\n",
       "      <td>2.035984</td>\n",
       "      <td>1.991618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>2.442784</td>\n",
       "      <td>2.738047</td>\n",
       "      <td>2.744106</td>\n",
       "      <td>2.189195</td>\n",
       "      <td>2.690643</td>\n",
       "      <td>2.211776</td>\n",
       "      <td>3.939318</td>\n",
       "      <td>1.982775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>2.239858</td>\n",
       "      <td>2.068203</td>\n",
       "      <td>2.195796</td>\n",
       "      <td>2.275679</td>\n",
       "      <td>2.118378</td>\n",
       "      <td>2.086651</td>\n",
       "      <td>1.936217</td>\n",
       "      <td>3.129322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          en_df     es_df     fr_df     in_df     it_df     nl_df     pt_df  \\\n",
       "en_df  4.309184  2.293770  2.532178  2.231851  2.123328  2.529614  1.927856   \n",
       "es_df  2.764492  4.392235  2.970475  2.393427  3.016536  2.456670  2.744862   \n",
       "fr_df  2.742375  2.544285  4.415564  2.285090  2.548024  2.547205  2.349252   \n",
       "in_df  2.373589  2.222998  2.429772  4.638793  2.267839  2.205126  2.006026   \n",
       "it_df  2.897508  3.137128  3.166326  2.543176  4.805001  2.564129  2.826795   \n",
       "nl_df  2.639346  2.318133  2.448077  2.224871  2.323701  4.408137  2.035984   \n",
       "pt_df  2.442784  2.738047  2.744106  2.189195  2.690643  2.211776  3.939318   \n",
       "tl_df  2.239858  2.068203  2.195796  2.275679  2.118378  2.086651  1.936217   \n",
       "\n",
       "          tl_df  \n",
       "en_df  2.091247  \n",
       "es_df  2.151533  \n",
       "fr_df  1.930364  \n",
       "in_df  2.193134  \n",
       "it_df  2.290382  \n",
       "nl_df  1.991618  \n",
       "pt_df  1.982775  \n",
       "tl_df  3.129322  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = True) model perlexity score per model and test language :\n",
      "\n",
      "n = 4, add_one = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>508.530267</td>\n",
       "      <td>23.936690</td>\n",
       "      <td>31.841270</td>\n",
       "      <td>23.722843</td>\n",
       "      <td>20.383399</td>\n",
       "      <td>34.786579</td>\n",
       "      <td>15.756271</td>\n",
       "      <td>22.562204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>37.661317</td>\n",
       "      <td>490.261217</td>\n",
       "      <td>48.807418</td>\n",
       "      <td>26.643679</td>\n",
       "      <td>55.125790</td>\n",
       "      <td>27.263883</td>\n",
       "      <td>48.998075</td>\n",
       "      <td>22.279463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>41.803938</td>\n",
       "      <td>34.671091</td>\n",
       "      <td>487.785233</td>\n",
       "      <td>23.403266</td>\n",
       "      <td>33.356777</td>\n",
       "      <td>31.785906</td>\n",
       "      <td>27.531624</td>\n",
       "      <td>16.962445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>23.213326</td>\n",
       "      <td>18.995776</td>\n",
       "      <td>23.279904</td>\n",
       "      <td>575.365148</td>\n",
       "      <td>19.580899</td>\n",
       "      <td>19.393979</td>\n",
       "      <td>15.179747</td>\n",
       "      <td>24.021276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>42.545316</td>\n",
       "      <td>61.597574</td>\n",
       "      <td>54.872547</td>\n",
       "      <td>30.531767</td>\n",
       "      <td>529.024349</td>\n",
       "      <td>29.819406</td>\n",
       "      <td>47.956677</td>\n",
       "      <td>26.428432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>35.123212</td>\n",
       "      <td>23.119273</td>\n",
       "      <td>26.256139</td>\n",
       "      <td>22.382840</td>\n",
       "      <td>21.143820</td>\n",
       "      <td>506.784157</td>\n",
       "      <td>16.656295</td>\n",
       "      <td>17.179881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>26.978216</td>\n",
       "      <td>43.931692</td>\n",
       "      <td>36.324480</td>\n",
       "      <td>21.313828</td>\n",
       "      <td>38.931561</td>\n",
       "      <td>21.210296</td>\n",
       "      <td>524.167062</td>\n",
       "      <td>17.443730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>24.041166</td>\n",
       "      <td>19.080509</td>\n",
       "      <td>20.448821</td>\n",
       "      <td>28.699707</td>\n",
       "      <td>19.909655</td>\n",
       "      <td>19.890651</td>\n",
       "      <td>16.344748</td>\n",
       "      <td>355.911777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            en_df       es_df       fr_df       in_df       it_df       nl_df  \\\n",
       "en_df  508.530267   23.936690   31.841270   23.722843   20.383399   34.786579   \n",
       "es_df   37.661317  490.261217   48.807418   26.643679   55.125790   27.263883   \n",
       "fr_df   41.803938   34.671091  487.785233   23.403266   33.356777   31.785906   \n",
       "in_df   23.213326   18.995776   23.279904  575.365148   19.580899   19.393979   \n",
       "it_df   42.545316   61.597574   54.872547   30.531767  529.024349   29.819406   \n",
       "nl_df   35.123212   23.119273   26.256139   22.382840   21.143820  506.784157   \n",
       "pt_df   26.978216   43.931692   36.324480   21.313828   38.931561   21.210296   \n",
       "tl_df   24.041166   19.080509   20.448821   28.699707   19.909655   19.890651   \n",
       "\n",
       "            pt_df       tl_df  \n",
       "en_df   15.756271   22.562204  \n",
       "es_df   48.998075   22.279463  \n",
       "fr_df   27.531624   16.962445  \n",
       "in_df   15.179747   24.021276  \n",
       "it_df   47.956677   26.428432  \n",
       "nl_df   16.656295   17.179881  \n",
       "pt_df  524.167062   17.443730  \n",
       "tl_df   16.344748  355.911777  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for matching (add_one = False) model perlexity score per model and test language :\n",
      "\n",
      "n = 4, add_one = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_df</th>\n",
       "      <th>es_df</th>\n",
       "      <th>fr_df</th>\n",
       "      <th>in_df</th>\n",
       "      <th>it_df</th>\n",
       "      <th>nl_df</th>\n",
       "      <th>pt_df</th>\n",
       "      <th>tl_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en_df</th>\n",
       "      <td>1.865606</td>\n",
       "      <td>1.121681</td>\n",
       "      <td>1.188322</td>\n",
       "      <td>1.114338</td>\n",
       "      <td>1.144030</td>\n",
       "      <td>1.156407</td>\n",
       "      <td>1.087554</td>\n",
       "      <td>1.080483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_df</th>\n",
       "      <td>1.155921</td>\n",
       "      <td>2.060650</td>\n",
       "      <td>1.269440</td>\n",
       "      <td>1.110383</td>\n",
       "      <td>1.309363</td>\n",
       "      <td>1.156332</td>\n",
       "      <td>1.248118</td>\n",
       "      <td>1.084723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_df</th>\n",
       "      <td>1.186430</td>\n",
       "      <td>1.233825</td>\n",
       "      <td>2.005493</td>\n",
       "      <td>1.104869</td>\n",
       "      <td>1.209101</td>\n",
       "      <td>1.156551</td>\n",
       "      <td>1.144624</td>\n",
       "      <td>1.069920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_df</th>\n",
       "      <td>1.124816</td>\n",
       "      <td>1.116398</td>\n",
       "      <td>1.113791</td>\n",
       "      <td>1.981470</td>\n",
       "      <td>1.134983</td>\n",
       "      <td>1.110769</td>\n",
       "      <td>1.090298</td>\n",
       "      <td>1.158461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it_df</th>\n",
       "      <td>1.166394</td>\n",
       "      <td>1.286207</td>\n",
       "      <td>1.231846</td>\n",
       "      <td>1.139954</td>\n",
       "      <td>2.184752</td>\n",
       "      <td>1.119157</td>\n",
       "      <td>1.185137</td>\n",
       "      <td>1.099106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_df</th>\n",
       "      <td>1.168725</td>\n",
       "      <td>1.150577</td>\n",
       "      <td>1.190717</td>\n",
       "      <td>1.108792</td>\n",
       "      <td>1.127843</td>\n",
       "      <td>1.978597</td>\n",
       "      <td>1.088746</td>\n",
       "      <td>1.074574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_df</th>\n",
       "      <td>1.141296</td>\n",
       "      <td>1.289672</td>\n",
       "      <td>1.219510</td>\n",
       "      <td>1.120374</td>\n",
       "      <td>1.255854</td>\n",
       "      <td>1.120441</td>\n",
       "      <td>1.837578</td>\n",
       "      <td>1.074569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl_df</th>\n",
       "      <td>1.147484</td>\n",
       "      <td>1.117438</td>\n",
       "      <td>1.137728</td>\n",
       "      <td>1.221908</td>\n",
       "      <td>1.148638</td>\n",
       "      <td>1.107226</td>\n",
       "      <td>1.105917</td>\n",
       "      <td>1.615895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          en_df     es_df     fr_df     in_df     it_df     nl_df     pt_df  \\\n",
       "en_df  1.865606  1.121681  1.188322  1.114338  1.144030  1.156407  1.087554   \n",
       "es_df  1.155921  2.060650  1.269440  1.110383  1.309363  1.156332  1.248118   \n",
       "fr_df  1.186430  1.233825  2.005493  1.104869  1.209101  1.156551  1.144624   \n",
       "in_df  1.124816  1.116398  1.113791  1.981470  1.134983  1.110769  1.090298   \n",
       "it_df  1.166394  1.286207  1.231846  1.139954  2.184752  1.119157  1.185137   \n",
       "nl_df  1.168725  1.150577  1.190717  1.108792  1.127843  1.978597  1.088746   \n",
       "pt_df  1.141296  1.289672  1.219510  1.120374  1.255854  1.120441  1.837578   \n",
       "tl_df  1.147484  1.117438  1.137728  1.221908  1.148638  1.107226  1.105917   \n",
       "\n",
       "          tl_df  \n",
       "en_df  1.080483  \n",
       "es_df  1.084723  \n",
       "fr_df  1.069920  \n",
       "in_df  1.158461  \n",
       "it_df  1.099106  \n",
       "nl_df  1.074574  \n",
       "pt_df  1.074569  \n",
       "tl_df  1.615895  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dict = run_match(data_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cg4h5Cl0q2nR"
   },
   "source": [
    "**Part 6**\n",
    "\n",
    "Each line in the file test.csv contains a sentence and the language it belongs to. Write a function that uses your language models to classify the correct language of each sentence.\n",
    "\n",
    "Important note regarding the grading of this section: this is an open question, where a different solution will yield different accuracy scores. any solution that is not trivial (e.g. returning 'en' in all cases) will be excepted. We do reserve the right to give bonus points to exceptionally good/creative solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls nlp-course\\lm-languages-data-new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = r'nlp-course\\lm-languages-data-new'\n",
    "test_csv_files =  glob.glob(test_folder + '\\\\*.csv')\n",
    "test_files =  {}\n",
    "for i_file in test_csv_files:\n",
    "    file_name_with_ending = os.path.basename(i_file)\n",
    "    file_name = os.path.splitext(file_name_with_ending)[0]\n",
    "    test_files[file_name + '_df'] = f'' + i_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD6IRIQLrlZF"
   },
   "outputs": [],
   "source": [
    "def match_test(n, model_dict, data_file_path, add_one):\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "    #data_file_path = r\"C:\\MSC\\NLP2\\nlp-course\\lm-languages-data-new\\test.csv\"\n",
    "    senstences_list = pd.read_csv(data_file_path)['tweet_text'].to_list()\n",
    "    lines = [] \n",
    "    result_dict = {}\n",
    "    for i_language_model in languages_list:\n",
    "        i_model = model_dict[n][add_one][i_language_model]\n",
    "        result_dict[i_language_model] = {}\n",
    "        \n",
    "        for i_test_senstence in senstences_list:\n",
    "            i_sentence_model_i_score = eval(n, i_model, i_test_senstence)\n",
    "            result_dict[i_language_model][i_test_senstence] = i_sentence_model_i_score\n",
    "    # print('summary for '+ i_language_model +' model perlexity score for each language:\\n')\n",
    "    perlexity_df = pd.DataFrame(result_dict)\n",
    "    print(perlexity_df)\n",
    "    #TODO\n",
    "    return perlexity_df\n",
    "\n",
    "\n",
    "def classify(n, model_dict, data_file_path, add_one):\n",
    "    # TODO\n",
    "    match_dict  = match_test(n, model_dict, data_file_path, add_one)\n",
    "    return match_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "test_path = test_folder + '\\\\test.csv'\n",
    "clasification_result = classify(n, model_dict, test_path, False)\n",
    "\n",
    "# roni needed to yuield results from mat results\n",
    "#########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5ECmLd3rktZ"
   },
   "source": [
    "**Part 7**\n",
    "\n",
    "Calculate the F1 score of your output from part 6. (hint: you can use https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOBO3YQls66r"
   },
   "outputs": [],
   "source": [
    "def calc_f1(result):\n",
    "    data_file_path = f'nlp-course/lm-languages-data-new/test.csv'\n",
    "    labels = pd.read_csv(data_file_path).get('label')\n",
    "    print(list(labels))\n",
    "    return f1_score(list(labels), clasification_result,average=\"micro\")\n",
    "\n",
    "  # TODO\n",
    "\n",
    "calc_f1(clasification_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEtckSWNANqW"
   },
   "source": [
    "# **Good luck!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
