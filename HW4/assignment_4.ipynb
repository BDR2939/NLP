{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Assignment 4\n",
        "Training a simple neural net for relation classification."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchinfo\n",
        "!pip install torch-info\n",
        "!pip install torchsummary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go_ia6t8DK0D",
        "outputId": "16917539-0ebb-4229-e7b1-58e9c06521b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 38.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-info (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch-info\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install turchsummary\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BoHBYieFpSN",
        "outputId": "49edf4c4-d0e8-426d-a425-925dc360e293"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement turchsummary (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for turchsummary\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9616673-3fbd-4163-e9ce-f3337ce18391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AutoConfig, AutoModel\n",
        "from torchsummary import summary\n",
        "from numpy.random import default_rng\n",
        "import gc\n",
        "import pandas as pd \n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh"
      },
      "source": [
        "In this assignment you are required :\n",
        "## to build a full training and testing pipeline for a neural relation classification (RC), using BERT.\n",
        "\n",
        "1. The dataset that you will be working on is called SemEval Task 8 dataset (https://arxiv.org/pdf/1911.10422v1.pdf). \n",
        "2. The dataset contain only train and test split, but you are allowed to split the train dataset into dev if needed.\n",
        "3. The two files (train and test) are available from the course git repository (https://github.com/kfirbar/nlp-course)\n",
        "4. In this work we will use the hugingface framework for transformers training and inference.\n",
        "5. We recomand reading the d4.ocumentation in https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification *before* you start coding. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "**Task 1:** \n",
        "## Write a funtion *read_data* for reading the data from a single file (either train or test). \n",
        "1. This function recieves a filepath and returns a list of sentence.\n",
        "2. Every sentence is encoded as a touple\n",
        "    * first element is the sentence string\n",
        "    * second the label (also represented as a sting). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_qzVkT2DJwC",
        "outputId": "c40fa999-849f-48a4-d5a8-483a6ab1f169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp-course'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 71 (delta 29), reused 40 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kfirbar/nlp-course"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# general folder path\n",
        "drive_path = '/content/gdrive'\n",
        "drive_saving_path = '/content/gdrive/My Drive'\n",
        "drive.mount(drive_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mqYtUDDV48",
        "outputId": "96468724-1a5a-4f31-d3a5-6e778670462c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HsHKQyyRDoIR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nSrPbGOUDJwD"
      },
      "outputs": [],
      "source": [
        "User = 'Drive'\n",
        "\n",
        "if User == 'Or':\n",
        "    train_path = r'C:\\MSC\\NLP2\\HW4\\TRAIN_FILE.TXT'\n",
        "    test_path = r'C:\\MSC\\NLP2\\HW4\\TEST_FILE_FULL.txt'\n",
        "else:\n",
        "    main_folder = os.path.join(drive_saving_path, 'NLP4')\n",
        "    train_path = os.path.join(main_folder, 'TRAIN_FILE.TXT')\n",
        "    test_path = os.path.join(main_folder, 'TEST_FILE_FULL.TXT')\n",
        "\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "prgzgtt8Jw4Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_data(filepath):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    filepath : string\n",
        "    DESCRIPTION:\n",
        "        1. for given path we read the txt file into list \n",
        "        2. for each sentence is shift of 4 index 0,4,8,....,4n, the label\n",
        "           is the same only from the index 1,5,9,...4n+1\n",
        "        3. first we will slice the sentences, and labels \n",
        "        4. for each setnence we will remodve the TAB & \"\\n\" \n",
        "            ([1:-1] to remove the double quating ) \n",
        "        \n",
        "          for each labels needed to remove  space and \"\\n\"\n",
        "        5. finnaly we need to concat setence to label to list of tupples \n",
        "    Returns\n",
        "    -------\n",
        "    data : list \n",
        "        list of tupples [ (sentence, label), (), ....].\n",
        "    \"\"\"\n",
        "    # 1\n",
        "    with open(filepath) as file:\n",
        "        output = file.readlines()\n",
        "    \n",
        "    # 2\n",
        "    STEP = 4\n",
        "    \n",
        "    # 3\n",
        "    labels  = output[1::STEP]\n",
        "    sentences  = output[0::STEP]\n",
        "\n",
        "    #4 \n",
        "    # sentence splited\n",
        "    sentences = list(map(lambda x: x.split('\\t')[1].replace('\\n', '').replace('</e2>', '').replace('</e1>', '').replace('<e1>', '').replace('<e2>', '')[1:-1], sentences))\n",
        "    labels = list(map(lambda x: x.replace('\\n', '').replace('(e2,e1)', '').replace('(e1,e2)', ''), labels))\n",
        "\n",
        "    # 5\n",
        "    data = list(zip(sentences, labels))\n",
        "    \n",
        "    return data\n",
        "\n",
        "train = read_data(train_path)\n",
        "test = read_data(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS"
      },
      "source": [
        "Pytorch require the labels to be integers. Create a mapper (dictionary) from the string labels to integers (starting zero). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6rKIB5o_vQO8"
      },
      "outputs": [],
      "source": [
        "def from_list_of_list_2_single_list(list_of_list):\n",
        "    # convertign list of list to single list with all ellements\n",
        "    flat_list = [item for sublist in list_of_list for item in sublist]\n",
        "    return flat_list\n",
        "\n",
        "def get_unique_tokens_and_token_indexs(data, is_sentence = True):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : list of tuples \n",
        "        contain list of tuples (sentences, labels)\n",
        "    is_sentence : Bollan\n",
        "        indicate whether to get setnece or label\n",
        "    \n",
        "    \n",
        "    1. get desire list sentences\\labels \n",
        "    2. split into tokens\n",
        "    3. convert to single list with all ellements\n",
        "    4. doing unique the list to get unique value and index \n",
        "    5. generate dict\\mapper from token 2 index\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    mapper_dict : dict\n",
        "        map from unique token to unique index\n",
        "\n",
        "    \"\"\"\n",
        "    #1\n",
        "    if is_sentence:\n",
        "        list_of_list = list(map(lambda x: x[0], data))\n",
        "\n",
        "    # label\n",
        "    else: \n",
        "        list_of_list = list(map(lambda x: x[1], data))\n",
        "    \n",
        "    #2\n",
        "    list_of_list_tokens = list(map(lambda x: x.split(' '), list_of_list))\n",
        "    #3\n",
        "    all_tokens = from_list_of_list_2_single_list(list_of_list_tokens)\n",
        "    #4\n",
        "    unique_tokens =list(set(all_tokens))\n",
        "    #5\n",
        "    mapper_dict = dict(zip(unique_tokens,np.arange(0, unique_tokens.__len__())))\n",
        "    return mapper_dict\n",
        "\n",
        "def create_label_mapper(data):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : list of tuples \n",
        "        contain list of tuples (sentences, labels)\n",
        "    Returns\n",
        "    -------\n",
        "    sentences_mapper : dict\n",
        "        map from unique token to unique index\n",
        "    labels_mapper : dict\n",
        "        map from unique token to unique index\n",
        "    \"\"\" \n",
        "    #sentences_mapper = get_unique_tokens_and_token_indexs(data, is_sentence = True)\n",
        "    labels_mapper = get_unique_tokens_and_token_indexs(data, is_sentence = False)\n",
        "    return labels_mapper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapper = create_label_mapper(train)\n",
        "labels = list(label_mapper.keys())\n",
        "num_labels = labels.__len__()\n",
        "label_mapper"
      ],
      "metadata": {
        "id": "VQA3oJQ-s_ii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4396c7d-6314-49c2-a1ab-4e321d11201e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cause-Effect': 2,\n",
              " 'Component-Whole': 4,\n",
              " 'Content-Container': 1,\n",
              " 'Entity-Destination': 6,\n",
              " 'Entity-Origin': 5,\n",
              " 'Instrument-Agency': 7,\n",
              " 'Member-Collection': 9,\n",
              " 'Message-Topic': 8,\n",
              " 'Other': 3,\n",
              " 'Product-Producer': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "**Task 2:** \n",
        "## Write a function *prepare_data* that \n",
        "1. takes one of the [train, test] datasets and convert each pair of (words,labels) to a pair of indexes. \n",
        "2. The function also aggregate the samples into batches. \n",
        "3. BERT Uses pretrained tokanization and embedding. \n",
        "4. you can access the tokanization and indexing using the BertTokenizer class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "noIY3zWKvhBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "58cc2650802e48f9923ad1efe202ff7e",
            "2f69c251908e4af7ae1b1cd802e9b737",
            "e394038987bf425a9b42fde0dfef0b87",
            "2de0592cae824e3d9cecaaaa85673abe",
            "426969c8fd474ee0a8727a7eb3807f35",
            "4418bd1386294169acc8218c43908879",
            "dcc9fcc1e42046f1979365ccfd68c889",
            "521d4605ff37444ca156ac584dd83cd0",
            "1c5f5ce70b304683bef9099cf4912b3b",
            "e4b52cebd41345a9ad8c965d9d78b161",
            "ebe33ad4804d419b9775187f0ad4dbb8",
            "3f9c0d5e359440d0b94bb45b7c53efc8",
            "573100a06da34ebaafab8fd0aac9a760",
            "9e70a24151234922a9aa8fc9962fd92c",
            "1a75891f021d47d7a24f427522f97a3d",
            "5ea222d8ebc5499792676cd91024d4b8",
            "c97aa59e264c4c2a957f3ccc66061893",
            "ca389d37301a4723b6c1739be609647d",
            "a6b367f71aea4462995380de3d31ae80",
            "ed3c03f6310147b0b0540abb7482e559",
            "df6f03cd1b2448019758d28ea23b4189",
            "637a5ac128ea4a419e226cb72a0a35a9",
            "e685bfebf44349798e7e577b9dd27496",
            "6b10b9b456fb406ea7fe2e3be11c1435",
            "e859b561e19247c5a21c59d2ab9d67db",
            "19ee4fad4c124a549b58cb9faebf43aa",
            "934abc550e42419885ce4920dc00f815",
            "b2b80e6b1f9445da8025f1ea1c239c38",
            "1fd28af0750144e58aee5542344447e6",
            "c51d389d8a434900baf4952474ea7459",
            "b695d199405946e0b2a5f88d3f81e94b",
            "3f96ea847cf44dbcbf8b975bd67e1e4b",
            "094641be84494d2abab3640511ea0c70"
          ]
        },
        "outputId": "7d375475-a3df-479a-864b-b418b16e56d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58cc2650802e48f9923ad1efe202ff7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f9c0d5e359440d0b94bb45b7c53efc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e685bfebf44349798e7e577b9dd27496"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_single_input(i_data, label_tuple_idx, labels_mapper, sentence_tuple_idx, tokenizer, num_labels = 10):\n",
        "    \"\"\"\n",
        "    getting tuple size 3 base data item  (tensor input, mask tensor, label iteger)\n",
        "    \"\"\"\n",
        "    # get setnece and label\n",
        "    i_sentence = i_data[sentence_tuple_idx]\n",
        "    i_label = i_data[label_tuple_idx]\n",
        "    # do tokenization to the setnence\n",
        "    # i_tensor_input = tokenizer(i_sentence, return_tensors=\"pt\")\n",
        "    i_tensor_input = tokenizer(i_sentence,  truncation=True, padding='max_length',return_tensors=\"pt\")\n",
        "\n",
        "    i_tensor_input = list(i_tensor_input.values())\n",
        "    # get label\n",
        "    i_label = labels_mapper[i_label]\n",
        "    # print(i_label)\n",
        "    label_array = np.zeros((1,num_labels))\n",
        "    label_array[0,int(i_label)] = 1 \n",
        "    i_label = torch.tensor(label_array)\n",
        "    # insert all to tupple\n",
        "    # single_input = (input_ids, attn_mask, i_label)\n",
        "    # single_input = (i_tensor_input, i_label)\n",
        "\n",
        "    return i_tensor_input, i_label\n",
        "\n",
        "def prepare_data(data, tokenizer, batch_size=8, num_labels = 10):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : list of tuples \n",
        "        contain list of tuples (sentences, labels)\n",
        "    tokenizer : generator of transformers pakage\n",
        "        for given sentence return dict of:\n",
        "            1. input idx - tensor\n",
        "            2. mask  - tensor \n",
        "            3. attention_mask - tensor\n",
        "            \n",
        "    batch_size : int, optional\n",
        "        DESCRIPTION. The default is 8, the size of batch, after 8 input model will do backprop'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data_sequences : list of tuples \n",
        "        the input to our model\n",
        "\n",
        "    \"\"\"\n",
        "    data_sequences = []\n",
        "    sentence_tuple_idx = 0\n",
        "    label_tuple_idx = 1\n",
        "\n",
        "    labels_mapper = create_label_mapper(data)\n",
        "    for sentence_idx, i_data in enumerate(data):\n",
        "      \n",
        "            \n",
        "        # \n",
        "        i_tensor_input, i_label = get_single_input(i_data, label_tuple_idx, labels_mapper, sentence_tuple_idx, tokenizer, num_labels)\n",
        "\n",
        "\n",
        "        # initiate batch input list\n",
        "        if sentence_idx ==0 or ids_tensor.shape[0]%batch_size == 0 :\n",
        "            # print(sentence_idx)\n",
        "            # print(batch_size)\n",
        "\n",
        "            ids_tensor = i_tensor_input[0]\n",
        "            idx_tensor = i_tensor_input[1]\n",
        "            attention_mask_tensor = i_tensor_input[2]\n",
        "            label_tensor = i_label\n",
        "        else:\n",
        "            # append batch data\n",
        "            # print(sentence_idx)\n",
        "            ids_tensor = torch.concat((ids_tensor, i_tensor_input[0]), axis = 0)\n",
        "            idx_tensor = torch.concat((idx_tensor, i_tensor_input[1]), axis = 0)\n",
        "            attention_mask_tensor = torch.concat((attention_mask_tensor, i_tensor_input[2]), axis = 0)\n",
        "            label_tensor = torch.concat((label_tensor, i_label), axis = 0)\n",
        "\n",
        "        # if batch list is fill append batch data to all data \n",
        "        if ids_tensor.shape[0]%(batch_size) == 0:\n",
        "            batch_data = [[ids_tensor, idx_tensor, attention_mask_tensor], label_tensor]\n",
        "            data_sequences.append(batch_data)\n",
        "    \n",
        "    padd_last_batch_size =  8 - ids_tensor.shape[0] \n",
        "    if padd_last_batch_size>0:\n",
        "        rng = default_rng()\n",
        "        choosen_idx = \\\n",
        "            rng.choice(range(0, data.__len__()-padd_last_batch_size), size=padd_last_batch_size, replace=False)\n",
        "        for i_idx in choosen_idx:\n",
        "            \n",
        "            i_data = data[i_idx]\n",
        "            \n",
        "            # get single input\n",
        "            i_tensor_input, i_label = get_single_input(i_data, label_tuple_idx, labels_mapper, sentence_tuple_idx, tokenizer)\n",
        "            \n",
        "            # append batch data\n",
        "            ids_tensor = torch.concat((ids_tensor, i_tensor_input[0]), axis = 0)\n",
        "            idx_tensor = torch.concat((idx_tensor, i_tensor_input[1]), axis = 0)\n",
        "            attention_mask_tensor = torch.concat((attention_mask_tensor, i_tensor_input[2]), axis = 0)\n",
        "            label_tensor = torch.concat((label_tensor, i_label), axis = 0)\n",
        "\n",
        "\n",
        "        # append batch data\n",
        "        batch_data = [[ids_tensor, idx_tensor, attention_mask_tensor], label_tensor]\n",
        "        data_sequences.append(batch_data)       \n",
        "\n",
        "    return data_sequences\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "train_sequences = prepare_data(train, tokenizer)\n",
        "test_sequences = prepare_data(test, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3n4cCb8wpXE"
      },
      "source": [
        "**Task 3:** \n",
        "## In this part we classify the sentences using the BertForSequenceClassification model.\n",
        "1. To save resources, we initialize the optimizer with the final layer of the model. \n",
        "2. You are also allowed to change the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "efvj5qvPxNJE"
      },
      "outputs": [],
      "source": [
        "def get_parameters(params):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : pythorch model.named_parameters()\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    layers : TYPE\n",
        "        DESCRIPTION.\n",
        "    \"\"\"\n",
        "    # initiate layers \n",
        "    layers = []\n",
        "    # run on all model layers \n",
        "    for name, param in params:\n",
        "        # set when on which layer needed to do backprop'\n",
        "        param.requires_grad = 'classifier' in name\n",
        "        # append layer\n",
        "        layers.append(param)\n",
        "        # print(name)\n",
        "\n",
        "    return layers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CCm56TDJwI"
      },
      "source": [
        "## laod  model and print his summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "1tG-4ObGDJwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743db1fa-13f3-4433-efb4-d6081d24964f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# constants\n",
        "batch_size = 8\n",
        "epochs = 80\n",
        "lr = 1e-2\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i_tensor_input = tokenizer('i love shira and my self and my mine to ', padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "# i_tensor_input2 = tokenizer('i pick my self', padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# i_tensor_input = list(i_tensor_input.values())\n",
        "# i_tensor_input2 = list(i_tensor_input2.values())\n"
      ],
      "metadata": {
        "id": "I-uiSPUargXM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  i_tensor_input11 = torch.concat((i_tensor_input[0], i_tensor_input2[0]), axis = 0)\n",
        "#  i_tensor_input22 = torch.concat((i_tensor_input[1], i_tensor_input2[1]), axis = 0)\n",
        "#  i_tensor_input33 = torch.concat((i_tensor_input[2], i_tensor_input2[2]), axis = 0)\n",
        "# label_tensor = torch.empty(2,num_labels)\n",
        "\n",
        "# logits = model(i_tensor_input11.to(device), i_tensor_input22.to(device), i_tensor_input33.to(device), return_dict=False)\n",
        "# logits\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# criterion(logits[0], label_tensor.to(device)).backward()\n",
        "\n",
        "# # inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "# # inputs\n",
        "# # labels = torch.tensor(1)\n",
        "# # labels\n",
        "# # model(**inputs)"
      ],
      "metadata": {
        "id": "t57hbdxPcOTH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logits[0].shape"
      ],
      "metadata": {
        "id": "ObIWVGOtu0zh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_sequences[0]"
      ],
      "metadata": {
        "id": "t02dazxUgglm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzhOffvjDJwJ"
      },
      "source": [
        "## set optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JF87VjIIDJwJ"
      },
      "outputs": [],
      "source": [
        "# Optimizer (ADAM is a fancy version of SGD)\n",
        "optimizer = torch.optim.Adam(get_parameters(model.named_parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "**Task 4:** \n",
        "## Write a training loop\n",
        "1. takes a BertForSequenceClassification model \n",
        "2. train for number of epochs to train on.\n",
        "3. The loss is always CrossEntropyLoss \n",
        "4. optimizer is always Adam. \n",
        "5. You are allowed to split the train to train and dev sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p1H3FZYTGBcp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "avkHfjT3k0HM"
      },
      "outputs": [],
      "source": [
        "def predict_batch_results(train_data):\n",
        "  prediction_res = []\n",
        "  for i_input in train_data:\n",
        "    # get inputs\n",
        "    i_input_ids = i_input['input_ids']\n",
        "    i_attn_mask = i_input['attention_mask']\n",
        "    i_token_type_ids = i_input['token_type_ids']\n",
        "\n",
        "    # predict results\n",
        "    logits = model(i_input_ids.to(device), i_attn_mask.to(device), i_token_type_ids.to(device))\n",
        "    i_logits = logits['logits']\n",
        "\n",
        "    # append results\n",
        "    prediction_res.append(i_logits)\n",
        "  return prediction_res\n",
        "\n",
        "\n",
        "\n",
        "def get_model_results(model, test_sequences):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Torch model  - \n",
        "        DESCRIPTION: LSTM model.\n",
        "    test_sequences : list\n",
        "        DESCRIPTION: input list of coupels [[word_tensor, lebel_tensor] , ...]\n",
        "    \n",
        "    the function get model results\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    all_test_words_pred : list\n",
        "    all_test_words_true : list\n",
        "    \"\"\"\n",
        "    # generate test tokens prediction\n",
        "    all_test_words_pred = []\n",
        "    all_test_words_true = []\n",
        "\n",
        "\n",
        "    # ids_tensor = list(map(lambda x: x[0][0], test_sequences))\n",
        "    # idx_tensor = list(map(lambda x: x[0][1], test_sequences))\n",
        "    # attention_mask_tensor = list(map(lambda x: x[0][2], test_sequences))\n",
        "    # labels = list(map(lambda x: x[1], test_sequences))\n",
        "\n",
        "    # ids_tensor = torch.concat((ids_tensor), axis = 0)\n",
        "    # idx_tensor = torch.concat((idx_tensor), axis = 0)\n",
        "    # attention_mask_tensor = torch.concat((attention_mask_tensor), axis = 0)\n",
        "    # labels = torch.concat((labels), axis = 0)\n",
        "    for sentence, labels in test_sequences:\n",
        "        ids_tensor = sentence[0]\n",
        "        idx_tensor = sentence[1]\n",
        "        attention_mask_tensor = sentence[2]\n",
        "\n",
        "        labels_tensor = labels.to(device)\n",
        "        logits = model(ids_tensor.to(device), idx_tensor.to(device), attention_mask_tensor.to(device))\n",
        "        logits = logits.logits\n",
        "        \n",
        "        _, pred_labels =logits.T.max(0)\n",
        "        _, labels =labels.T.max(0)\n",
        "\n",
        "        all_test_words_pred += pred_labels.tolist()\n",
        "        all_test_words_true += labels.tolist()\n",
        "\n",
        "    return all_test_words_pred, all_test_words_true\n",
        "\n",
        "def train_loop(model, n_epochs, train_data, label_mapper, dev_data = None, alpha_zero = 1e-3 ):\n",
        "\n",
        "  update_lr_after_n_aphoc = 1  \n",
        "  # alpha_zero = 1e-2\n",
        "  # Loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  all_target_names = list(label_mapper.keys())\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=alpha_zero)\n",
        "\n",
        "  \n",
        "  curr_f1_accuracy_result = 0\n",
        "  best_f1_accuracy_result = 0\n",
        "  best_df = pd.DataFrame()\n",
        "  old_lr  = alpha_zero\n",
        "  for ephoc_index in range(1, n_epochs + 1):\n",
        "\n",
        "    desc = ('Ephoc #' + str(ephoc_index))\n",
        "    for sequence_idx in tqdm_notebook(range(train_data.__len__()), desc = desc):\n",
        "        \n",
        "        \n",
        "        # get sentence tokens, and labels \n",
        "        batch_data =  train_sequences[sequence_idx]\n",
        "\n",
        "        train_data = batch_data[0]\n",
        "        train_labels = batch_data[1]\n",
        "\n",
        "        # input_ids_train ,train_attention_mask, train_labels = train_sequences[sequence_idx]\n",
        "        if not dev_data is None:\n",
        "            dev_sentence ,dev_mask, dev_labels = train_sequences[sequence_idx]\n",
        "\n",
        "        # check if there is empty sentence\n",
        "        if train_labels.shape[0] == 0:\n",
        "            continue\n",
        "    \n",
        "        \n",
        "        # Sets the gradients of all optimized to zero.\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # foward sentence to model\n",
        "        ids_tensor = train_data[0]\n",
        "        idx_tensor = train_data[1]\n",
        "        attention_mask_tensor = train_data[2]\n",
        "        logits = model(ids_tensor.to(device), idx_tensor.to(device), attention_mask_tensor.to(device))\n",
        "        logits = logits.logits\n",
        "\n",
        "        # Computes the gradient of current tensor\n",
        "        criterion(logits, train_labels.to(device)).backward()\n",
        "        \n",
        "        # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # once the gradients are computed use them to optimize model\n",
        "        optimizer.step()\n",
        "    \n",
        "    \n",
        "    cos_inner = np.pi * (ephoc_index % (n_epochs // update_lr_after_n_aphoc))  \n",
        "    cos_inner /= n_epochs // update_lr_after_n_aphoc\n",
        "    cos_out = np.cos(cos_inner) + 1\n",
        "    new_lr = float(alpha_zero / 2 * cos_out) # needed to be seen\n",
        "    lr_string = '\\nlearning rate we decay from value = ' + str(new_lr) + ' to the value = '+ str(old_lr)\n",
        "    old_lr  = new_lr\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=new_lr)\n",
        "\n",
        "    # torch.cuda.empty_cache()\n",
        "    # gc.collect()\n",
        "    print('finshed ephoc #' + str(ephoc_index) + ', ephoch results:' , flush = True)\n",
        "    all_train_words_pred, all_train_words_true = get_model_results(model, train_sequences)\n",
        "    curr_f1_accuracy_result = f1_score(all_train_words_true, all_train_words_pred,  average='macro')\n",
        "\n",
        "    # train_Results_df = pd.DataFrame(classification_report(all_train_words_true, all_train_words_pred, target_names = all_target_names, output_dict = True))\n",
        "    # curr_f1_accuracy_result = train_Results_df.iloc[2]['accuracy']\n",
        "\n",
        "    if curr_f1_accuracy_result > best_f1_accuracy_result:\n",
        "      improve_string = 'f1-accuracy-score improve from ' + str(best_f1_accuracy_result) + ' to ' + str(curr_f1_accuracy_result) \n",
        "      best_f1_accuracy_result = curr_f1_accuracy_result\n",
        "      # best_df = train_Results_df\n",
        "    else:\n",
        "      improve_string = 'f1-accuracy-score did not improve from ' + str(best_f1_accuracy_result)  \n",
        "    improve_string += lr_string\n",
        "    print(improve_string, flush = True)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "  return model \n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # train_fn, val_fn = train_test_split(train_fn, stratify=train_df.my_labels,test_size=0.1,random_state=10)\n"
      ],
      "metadata": {
        "id": "xpwfDYLuMUPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # get sentence tokens, and labels \n",
        "# batch_data =  train_sequences[0]\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# train_data = batch_data[0]\n",
        "# train_labels = batch_data[1]\n",
        "\n",
        "# # Sets the gradients of all optimized to zero.\n",
        "# model.zero_grad()\n",
        "\n",
        "# # foward sentence to model\n",
        "# ids_tensor = train_data[0]\n",
        "# idx_tensor = train_data[1]\n",
        "# attention_mask_tensor = train_data[2]\n",
        "# logits = model(ids_tensor.to(device), idx_tensor.to(device), attention_mask_tensor.to(device))\n",
        "# logits = logits.logits\n",
        "# logits\n",
        "\n",
        "\n",
        "\n",
        "# # Computes the gradient of current tensor\n",
        "# criterion(logits, train_labels.to(device)).backward()\n",
        "\n",
        "# # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "# torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "# # once the gradients are computed use them to optimize model\n",
        "# optimizer.step()"
      ],
      "metadata": {
        "id": "1omyAq834r7M"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_target_names = list(label_mapper.keys())\n",
        "# all_target_names.__len__()\n",
        "# all_target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6wf3HQl9IgG",
        "outputId": "ed87d716-637b-42a1-af49-2377932ff88e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Product-Producer',\n",
              " 'Content-Container',\n",
              " 'Cause-Effect',\n",
              " 'Other',\n",
              " 'Component-Whole',\n",
              " 'Entity-Origin',\n",
              " 'Entity-Destination',\n",
              " 'Instrument-Agency',\n",
              " 'Message-Topic',\n",
              " 'Member-Collection']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "all_train_words_pred, all_train_words_true = get_model_results(model, train_sequences[0:100])\n",
        "all_train_words_pred\n",
        "all_train_words_true\n",
        "all_target_names = list(label_mapper.keys())\n",
        "f1_score(all_train_words_true, all_train_words_pred,  average='macro')\n",
        "# train_Results_df = pd.DataFrame(classification_report(all_train_words_true, all_train_words_pred, target_names = all_target_names, output_dict = True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhD88G235SJJ",
        "outputId": "1ae3aa00-d96a-4d2b-fd8f-0d0b0267f085"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.026652221018418198"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_words_pred.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXCMAAYpGqlX",
        "outputId": "918ed22a-5003-426d-f9a3-34739a5b7e70"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all_train_words_true\n",
        "# # all_train_words_pred\n",
        "# # all_target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLBAi-z__Cuk",
        "outputId": "9529bb61-131b-4b20-bb4d-86c9fd2d95ee"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Product-Producer',\n",
              " 'Content-Container',\n",
              " 'Cause-Effect',\n",
              " 'Other',\n",
              " 'Component-Whole',\n",
              " 'Entity-Origin',\n",
              " 'Entity-Destination',\n",
              " 'Instrument-Agency',\n",
              " 'Message-Topic',\n",
              " 'Member-Collection']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt = train_sequences[0:20]"
      ],
      "metadata": {
        "id": "uDB5K9ObDg5J"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ids_tensor = list(map(lambda x: x[0][0], tt))\n",
        "# idx_tensor = list(map(lambda x: x[0][1], tt))\n",
        "# attention_mask_tensor = list(map(lambda x: x[0][2], tt))\n",
        "# labels = list(map(lambda x: x[1], tt))\n",
        "\n",
        "# ids_tensor = torch.concat((ids_tensor), axis = 0)\n",
        "# idx_tensor = torch.concat((idx_tensor), axis = 0)\n",
        "# attention_mask_tensor = torch.concat((attention_mask_tensor), axis = 0)\n",
        "# labels = torch.concat((labels), axis = 0)\n",
        "\n",
        "# logits = model(ids_tensor.to(device), idx_tensor.to(device), attention_mask_tensor.to(device))\n",
        "# logits = logits.logits\n",
        "# logits\n",
        "\n",
        "\n",
        "# for sentence, labels in test_sequences:\n",
        "#     ids_tensor = sentence[0]\n",
        "#     idx_tensor = sentence[1]\n",
        "#     attention_mask_tensor = sentence[2]\n",
        "\n",
        "#     labels_tensor = labels.to(device)\n",
        "#     logits = model(ids_tensor.to(device), idx_tensor.to(device), attention_mask_tensor.to(device))\n",
        "#     logits = logits.logits\n",
        "    \n",
        "#     _, pred_labels =logits.T.max(0)\n",
        "#     _, labels =labels.T.max(0)\n",
        "\n",
        "#     all_test_words_pred += pred_labels.tolist()\n",
        "#     all_test_words_true += labels.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "cq0coWpA_4Tn",
        "outputId": "1c1f331e-8116-42b0-ab81-0ddda07f25de"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-63d9510587c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# logits = logits.logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         )\n\u001b[1;32m   1565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         )\n\u001b[1;32m   1029\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m                 )\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         )\n\u001b[1;32m    500\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.88 GiB (GPU 0; 15.90 GiB total capacity; 14.50 GiB already allocated; 183.75 MiB free; 14.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIClioI6E50e",
        "outputId": "ca3c65d9-75a6-41a2-cdf3-22e5817777db"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5494"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_Results_df = pd.DataFrame(classification_report(all_train_words_true, all_train_words_true, target_names = all_target_names, output_dict = True, zero_division = 0))\n",
        "# train_Results_df\n",
        "train_sequences.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6MXMfH7--CV",
        "outputId": "25b689bc-d18f-415e-a4d3-4bddcad8658b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a12a55bfc3434193a52e92f48ac93ddb",
            "c3bd321f4e1843b186566a36ad835ac2",
            "0fff1719039948448c4bf7ee36942851",
            "cd5e173ffaf9431fbd6ba31c259d0e6a",
            "f4edeb2e95cc468691aca8c0739bbf0e",
            "7a7c09b899ef4996a44490d59341eb8d",
            "083af28181d24dcb9ea655674ce43c67",
            "e11b4e3a1b0c488f9c7b3a19a73edd28",
            "cf159344607a4eb9a4baebc76853d0e8",
            "1d563b83e33a4635a9cb302d1861f372",
            "d46a5b793ca5402692c0ae30e0ed561c"
          ]
        },
        "id": "sQVHRlmYDJwK",
        "outputId": "f165b033-dff8-49fb-8fb0-2ae69946204e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Ephoc #1:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a12a55bfc3434193a52e92f48ac93ddb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = train_loop(model, n_epochs=10, train_data=train_sequences, label_mapper = label_mapper, dev_data=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "**Task 5:** write an evaluation loop on a trained model, using the dev and test datasets. This function print the true positive rate (TPR), also known as Recall and the opposite to false positive rate (FPR), also known as precision, of each label seperately (10 labels in total), and for all labels together. The caption argument for the function should be served for printing, so that when you print include it as a prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQAjGaqmd8U"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_data):\n",
        "  # TODO - your code goes here\n",
        "  print(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjkeUfncUl42"
      },
      "source": [
        "**Task 6:** In this part we'll improve the model accuracy by using a method called \"entity markers - Entity start\". The main idea of this approch is to add special markers ([e1], [\\e1], ...) before and after each of the tagged entities. instead of using the CLS toekn for clasification, we will use the concatination of the embedding of [e1] and [e2] as shown in the image below. The complete method is described in details in the following paper - https://arxiv.org/pdf/1906.03158.pdf (specifically in Section 3.2). To use this method we'll need to create a new data load and a new model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKhIbJuzc_EE"
      },
      "source": [
        "![Capture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTRk1T81VoXj"
      },
      "source": [
        "The new methods require the usage of special tokens. The following code will add the required tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU8jayVXYGsK"
      },
      "outputs": [],
      "source": [
        "tokenizer.add_tokens(['[E1]', '[/E1]', '[E2]', '[/E2]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2UMaxjFYOB7"
      },
      "source": [
        "Create a new dataloader that add entity markers to the dataset and return their indexes as part of the new sample (the expected sample should be (s, l, i) where s is the sentence embedding, l is the label, and i is a touple with the indexes of the start entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMMMR1kSYnc3"
      },
      "outputs": [],
      "source": [
        "def prepare_data_MTB(data, tokenizer, batch_size=8):\n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "\n",
        "    return data_sequences\n",
        "\n",
        "train_sequences = prepare_data_MTB(train, tokenizer)\n",
        "test_sequences = prepare_data_MTB(test, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AztAwecuYyt3"
      },
      "source": [
        "Create a new model that uses the \"entity markers - Entity start\" method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADpFlxPFY5mD"
      },
      "outputs": [],
      "source": [
        "class MTB(nn.Module):\n",
        "    def __init__(self, base_model_name):\n",
        "      config = AutoConfig.from_pretrained(name)\n",
        "      self.model = AutoModel.from_config(config)\n",
        "      # TODO - your code...\n",
        "    def forward(self, input, index):\n",
        "      # TODO - your code...\n",
        "model = MTB('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwCczHeZjaw"
      },
      "source": [
        "Use the new dataloader and model to train and evaluate the new model as in task 4 and 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k46XVrTHZxcu"
      },
      "outputs": [],
      "source": [
        "train_loop(model, n_epochs, train_data, dev_data)\n",
        "evaluate(model, test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV"
      },
      "source": [
        "**Good luck!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "assignment_4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58cc2650802e48f9923ad1efe202ff7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f69c251908e4af7ae1b1cd802e9b737",
              "IPY_MODEL_e394038987bf425a9b42fde0dfef0b87",
              "IPY_MODEL_2de0592cae824e3d9cecaaaa85673abe"
            ],
            "layout": "IPY_MODEL_426969c8fd474ee0a8727a7eb3807f35"
          }
        },
        "2f69c251908e4af7ae1b1cd802e9b737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4418bd1386294169acc8218c43908879",
            "placeholder": "​",
            "style": "IPY_MODEL_dcc9fcc1e42046f1979365ccfd68c889",
            "value": "Downloading: 100%"
          }
        },
        "e394038987bf425a9b42fde0dfef0b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521d4605ff37444ca156ac584dd83cd0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c5f5ce70b304683bef9099cf4912b3b",
            "value": 231508
          }
        },
        "2de0592cae824e3d9cecaaaa85673abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b52cebd41345a9ad8c965d9d78b161",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe33ad4804d419b9775187f0ad4dbb8",
            "value": " 226k/226k [00:00&lt;00:00, 286kB/s]"
          }
        },
        "426969c8fd474ee0a8727a7eb3807f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4418bd1386294169acc8218c43908879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc9fcc1e42046f1979365ccfd68c889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521d4605ff37444ca156ac584dd83cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5f5ce70b304683bef9099cf4912b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4b52cebd41345a9ad8c965d9d78b161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe33ad4804d419b9775187f0ad4dbb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f9c0d5e359440d0b94bb45b7c53efc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_573100a06da34ebaafab8fd0aac9a760",
              "IPY_MODEL_9e70a24151234922a9aa8fc9962fd92c",
              "IPY_MODEL_1a75891f021d47d7a24f427522f97a3d"
            ],
            "layout": "IPY_MODEL_5ea222d8ebc5499792676cd91024d4b8"
          }
        },
        "573100a06da34ebaafab8fd0aac9a760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c97aa59e264c4c2a957f3ccc66061893",
            "placeholder": "​",
            "style": "IPY_MODEL_ca389d37301a4723b6c1739be609647d",
            "value": "Downloading: 100%"
          }
        },
        "9e70a24151234922a9aa8fc9962fd92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b367f71aea4462995380de3d31ae80",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed3c03f6310147b0b0540abb7482e559",
            "value": 28
          }
        },
        "1a75891f021d47d7a24f427522f97a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df6f03cd1b2448019758d28ea23b4189",
            "placeholder": "​",
            "style": "IPY_MODEL_637a5ac128ea4a419e226cb72a0a35a9",
            "value": " 28.0/28.0 [00:00&lt;00:00, 669B/s]"
          }
        },
        "5ea222d8ebc5499792676cd91024d4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97aa59e264c4c2a957f3ccc66061893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca389d37301a4723b6c1739be609647d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b367f71aea4462995380de3d31ae80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3c03f6310147b0b0540abb7482e559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df6f03cd1b2448019758d28ea23b4189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637a5ac128ea4a419e226cb72a0a35a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e685bfebf44349798e7e577b9dd27496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b10b9b456fb406ea7fe2e3be11c1435",
              "IPY_MODEL_e859b561e19247c5a21c59d2ab9d67db",
              "IPY_MODEL_19ee4fad4c124a549b58cb9faebf43aa"
            ],
            "layout": "IPY_MODEL_934abc550e42419885ce4920dc00f815"
          }
        },
        "6b10b9b456fb406ea7fe2e3be11c1435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b80e6b1f9445da8025f1ea1c239c38",
            "placeholder": "​",
            "style": "IPY_MODEL_1fd28af0750144e58aee5542344447e6",
            "value": "Downloading: 100%"
          }
        },
        "e859b561e19247c5a21c59d2ab9d67db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51d389d8a434900baf4952474ea7459",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b695d199405946e0b2a5f88d3f81e94b",
            "value": 570
          }
        },
        "19ee4fad4c124a549b58cb9faebf43aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f96ea847cf44dbcbf8b975bd67e1e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_094641be84494d2abab3640511ea0c70",
            "value": " 570/570 [00:00&lt;00:00, 4.02kB/s]"
          }
        },
        "934abc550e42419885ce4920dc00f815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b80e6b1f9445da8025f1ea1c239c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd28af0750144e58aee5542344447e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c51d389d8a434900baf4952474ea7459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b695d199405946e0b2a5f88d3f81e94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f96ea847cf44dbcbf8b975bd67e1e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094641be84494d2abab3640511ea0c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12a55bfc3434193a52e92f48ac93ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3bd321f4e1843b186566a36ad835ac2",
              "IPY_MODEL_0fff1719039948448c4bf7ee36942851",
              "IPY_MODEL_cd5e173ffaf9431fbd6ba31c259d0e6a"
            ],
            "layout": "IPY_MODEL_f4edeb2e95cc468691aca8c0739bbf0e"
          }
        },
        "c3bd321f4e1843b186566a36ad835ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7c09b899ef4996a44490d59341eb8d",
            "placeholder": "​",
            "style": "IPY_MODEL_083af28181d24dcb9ea655674ce43c67",
            "value": "Ephoc #1:   9%"
          }
        },
        "0fff1719039948448c4bf7ee36942851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11b4e3a1b0c488f9c7b3a19a73edd28",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf159344607a4eb9a4baebc76853d0e8",
            "value": 91
          }
        },
        "cd5e173ffaf9431fbd6ba31c259d0e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d563b83e33a4635a9cb302d1861f372",
            "placeholder": "​",
            "style": "IPY_MODEL_d46a5b793ca5402692c0ae30e0ed561c",
            "value": " 91/1000 [00:40&lt;06:41,  2.27it/s]"
          }
        },
        "f4edeb2e95cc468691aca8c0739bbf0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7c09b899ef4996a44490d59341eb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083af28181d24dcb9ea655674ce43c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11b4e3a1b0c488f9c7b3a19a73edd28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf159344607a4eb9a4baebc76853d0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d563b83e33a4635a9cb302d1861f372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46a5b793ca5402692c0ae30e0ed561c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}